{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1690394930548,"user":{"displayName":"Santosh Bhamidipati","userId":"03330145564595875028"},"user_tz":-330},"id":"QIF5qC216NPX","outputId":"ff1b374a-efde-4385-e6f7-533261408ea6"},"outputs":[{"output_type":"stream","name":"stdout","text":["69\n","29\n","['Albania,ALB,2014,7.21', 'Algeria,DZA,2014,6.75', 'Argentina,ARG,2014,2.88', 'Armenia,ARM,2014,5.24', 'Australia,AUS,2014,1.81', 'Austria,AUT,2014,1.95', 'Bangladesh,BGD,2014,3.77', 'Belgium,BEL,2014,1.69']\n","['albania,alb,2014,7.21', 'algeria,dza,2014,6.75', 'argentina,arg,2014,2.88', 'armenia,arm,2014,5.24', 'australia,aus,2014,1.81', 'austria,aut,2014,1.95', 'bangladesh,bgd,2014,3.77', 'belgium,bel,2014,1.69']\n","{1: ' ', 2: ',', 3: '.', 4: '0', 5: '1', 6: '2', 7: '3', 8: '4', 9: '5', 10: '6', 11: '7', 12: '8', 13: '9', 14: 'a', 15: 'b', 16: 'c', 17: 'd', 18: 'e', 19: 'f', 20: 'g', 21: 'h', 22: 'i', 23: 'j', 24: 'k', 25: 'l', 26: 'm', 27: 'n', 28: 'o', 29: 'p', 30: 'r', 31: 's', 32: 't', 33: 'u', 34: 'v', 35: 'w', 36: 'x', 37: 'y', 38: 'z', 0: '*'}\n","39\n","torch.Size([1233, 8]) torch.Size([1233])\n","torch.Size([169, 8]) torch.Size([169])\n","torch.Size([141, 8]) torch.Size([141])\n","******** --> c\n","*******c --> o\n","******co --> l\n","*****col --> o\n","****colo --> m\n","***colom --> b\n","**colomb --> i\n","*colombi --> a\n","colombia --> ,\n","olombia, --> c\n","lombia,c --> o\n","ombia,co --> l\n","mbia,col --> ,\n","bia,col, --> 2\n","ia,col,2 --> 0\n","a,col,20 --> 1\n",",col,201 --> 4\n","col,2014 --> ,\n","ol,2014, --> 3\n","l,2014,3 --> .\n"]}],"source":["import torch\n","import torch.nn.functional as F\n","import matplotlib.pyplot as plt # for making figures\n","%matplotlib inline\n","# read in all the words\n","words = open('names.csv', 'r').read().splitlines()[1:]\n","print(len(words))\n","print(max(len(w) for w in words))\n","print(words[:8])\n","words_orig = words\n","words = [w.lower() for w in words_orig]\n","print(words[:8])\n","# build the vocabulary of characters and mappings to/from integers\n","chars = sorted(list(set(''.join(words))))\n","stoi = {s:i+1 for i,s in enumerate(chars)}\n","stoi['*'] = 0\n","#stoi[';'] = 39\n","itos = {i:s for s,i in stoi.items()}\n","vocab_size = len(itos)\n","print(itos)\n","print(vocab_size)\n","# shuffle up the words\n","import random\n","random.seed(42)\n","random.shuffle(words)\n","# build the dataset\n","block_size = 8 # context length: how many characters do we take to predict the next one?\n","\n","def build_dataset(words):\n","  X, Y = [], []\n","\n","  for w in words:\n","    context = [0] * block_size\n","    for ch in w + '*':\n","      ix = stoi[ch]\n","      X.append(context)\n","      Y.append(ix)\n","      context = context[1:] + [ix] # crop and append\n","\n","  X = torch.tensor(X)\n","  Y = torch.tensor(Y)\n","  print(X.shape, Y.shape)\n","  return X, Y\n","\n","n1 = int(0.8*len(words))\n","n2 = int(0.9*len(words))\n","Xtr,  Ytr  = build_dataset(words[:n1])     # 80%\n","Xdev, Ydev = build_dataset(words[n1:n2])   # 10%\n","Xte,  Yte  = build_dataset(words[n2:])     # 10%\n","for x,y in zip(Xtr[:20], Ytr[:20]):\n","  print(''.join(itos[ix.item()] for ix in x), '-->', itos[y.item()])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"op2t_Yfq6NPd"},"outputs":[],"source":["torch.manual_seed(42); # seed rng for reproducibility"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hbhGDd8F3uFy"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","\n","class Linear(nn.Module):\n","    def __init__(self, fan_in, fan_out, bias=True):\n","        super(Linear, self).__init__()\n","        self.weight = nn.Parameter(torch.randn((fan_in, fan_out)) / fan_in**0.5)  # note: kaiming init\n","        if bias:\n","            self.bias = nn.Parameter(torch.zeros(fan_out))\n","        else:\n","            self.register_parameter('bias', None)\n","\n","    def forward(self, x):\n","        out = x @ self.weight\n","        if self.bias is not None:\n","            out += self.bias\n","        return out\n","\n","class BatchNorm1d(nn.Module):\n","    def __init__(self, dim, eps=1e-5, momentum=0.1):\n","        super(BatchNorm1d, self).__init__()\n","        self.eps = eps\n","        self.momentum = momentum\n","        self.training = True\n","        # Parameters (trained with backprop)\n","        self.gamma = nn.Parameter(torch.ones(dim))\n","        self.beta = nn.Parameter(torch.zeros(dim))\n","        # Buffers (trained with a running 'momentum update')\n","        self.register_buffer('running_mean', torch.zeros(dim))\n","        self.register_buffer('running_var', torch.ones(dim))\n","\n","    def forward(self, x):\n","        # Calculate the forward pass\n","        if self.training:\n","            if x.ndim == 2:\n","                dim = 0\n","            elif x.ndim == 3:\n","                dim = (0, 1)\n","            xmean = x.mean(dim, keepdim=True)  # Batch mean\n","            xvar = x.var(dim, keepdim=True)  # Batch variance\n","        else:\n","            xmean = self.running_mean\n","            xvar = self.running_var\n","        xhat = (x - xmean) / torch.sqrt(xvar + self.eps)  # Normalize to unit variance\n","        self.out = self.gamma * xhat + self.beta\n","        # Update the buffers\n","        if self.training:\n","            with torch.no_grad():\n","                self.running_mean = (1 - self.momentum) * self.running_mean + self.momentum * xmean\n","                self.running_var = (1 - self.momentum) * self.running_var + self.momentum * xvar\n","        return self.out\n","\n","    def parameters(self):\n","        return [self.gamma, self.beta]\n","\n","\n","class Embedding(nn.Module):\n","    def __init__(self, num_embeddings, embedding_dim):\n","        super(Embedding, self).__init__()\n","        self.embedding = nn.Embedding(num_embeddings, embedding_dim)\n","\n","    def forward(self, IX):\n","        return self.embedding(IX)\n","\n","class FlattenConsecutive(nn.Module):\n","    def __init__(self, n):\n","        super(FlattenConsecutive, self).__init__()\n","        self.n = n\n","\n","    def forward(self, x):\n","        B, T, C = x.shape\n","        x = x.view(B, T // self.n, C * self.n)\n","        if x.shape[1] == 1:\n","            x = x.squeeze(1)\n","        return x\n","\n","class Sequential(nn.Module):\n","    def __init__(self, layers):\n","        super(Sequential, self).__init__()\n","        self.layers = nn.ModuleList(layers)\n","\n","    def forward(self, x):\n","        for layer in self.layers:\n","            x = layer(x)\n","        return x\n","\n","# Definition of the Tanh class\n","class Tanh(nn.Module):\n","    def __call__(self, x):\n","        self.out = torch.tanh(x)\n","        return self.out\n","\n","import torch\n","import torch.nn as nn\n","\n","# ... (the rest of your code)\n","\n","class ReLU(nn.Module):\n","    def forward(self, x):\n","        return torch.relu(x)\n","\n","# Now, you can create the model with ReLU activation\n","#n_embd = 30\n","#n_hidden = 512\n","#model = Sequential([\n","#    Embedding(vocab_size, n_embd),\n","#    FlattenConsecutive(2), Linear(n_embd * 2, n_hidden, bias=False), BatchNorm1d(n_hidden), ReLU(),\n","#    FlattenConsecutive(2), Linear(n_hidden*2, n_hidden, bias=False), BatchNorm1d(n_hidden), ReLU(),\n","#    FlattenConsecutive(2), Linear(n_hidden*2, n_hidden, bias=False), BatchNorm1d(n_hidden), ReLU(),\n","#    Linear(n_hidden, vocab_size),\n","#])\n","\n","\n","# Now, you can create the model as before\n","#n_embd = 30\n","#n_hidden = 512\n","#model = Sequential([\n","#    Embedding(vocab_size, n_embd),\n","#    FlattenConsecutive(2), Linear(n_embd * 2, n_hidden, bias=False), BatchNorm1d(n_hidden), Tanh(),\n","#    FlattenConsecutive(2), Linear(n_hidden*2, n_hidden, bias=False), BatchNorm1d(n_hidden), Tanh(),\n","#    FlattenConsecutive(2), Linear(n_hidden*2, n_hidden, bias=False), BatchNorm1d(n_hidden), Tanh(),\n","#    Linear(n_hidden, vocab_size),\n","#])\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":511},"id":"qurAfVBC4KoG","executionInfo":{"status":"ok","timestamp":1690395554243,"user_tz":-330,"elapsed":619721,"user":{"displayName":"Santosh Bhamidipati","userId":"03330145564595875028"}},"outputId":"6e0d3515-3d2d-4a99-9c4d-5163cbc59b51"},"outputs":[{"output_type":"stream","name":"stdout","text":["Training on device: cuda\n","      0/ 200000: 3.6702\n","  10000/ 200000: 2.0494\n","  20000/ 200000: 1.6728\n","  30000/ 200000: 1.5162\n","  40000/ 200000: 1.4699\n","  50000/ 200000: 1.3895\n","  60000/ 200000: 1.2848\n","  70000/ 200000: 1.1982\n","  80000/ 200000: 1.2678\n","  90000/ 200000: 1.0200\n"," 100000/ 200000: 1.0858\n"," 110000/ 200000: 0.7860\n"," 120000/ 200000: 0.6583\n"," 130000/ 200000: 0.7418\n"," 140000/ 200000: 0.6952\n"," 150000/ 200000: 0.5850\n"," 160000/ 200000: 0.6808\n"," 170000/ 200000: 0.5835\n"," 180000/ 200000: 0.4978\n"," 190000/ 200000: 0.5803\n","CPU times: user 10min 1s, sys: 9.58 s, total: 10min 11s\n","Wall time: 10min 20s\n"]},{"output_type":"execute_result","data":{"text/plain":["'for i in range(max_steps):\\n    # Minibatch construction\\n    ix = torch.randint(0, Xtr.shape[0], (batch_size,), device=device)\\n    Xb, Yb = Xtr[ix], Ytr[ix]  # Batch X,Y\\n\\n    # Forward pass\\n    logits = model(Xb)\\n    loss = F.cross_entropy(logits, Yb)\\n\\n    # L2 regularization (weight decay)\\n    l2_regularization = 0.0\\n    for param in model.parameters():\\n        l2_regularization += torch.norm(param, p=2) ** 2\\n\\n    loss += weight_decay * l2_regularization\\n\\n    # Backward pass\\n    optimizer.zero_grad()\\n    loss.backward()\\n\\n    # Update: simple SGD\\n    lr = 0.001 if i < 150000 else 0.01  # Step learning rate decay\\n    optimizer.step()\\n\\n    # Track stats\\n    if i % 10000 == 0:\\n        print(f\"{i:7d}/{max_steps:7d}: {loss.item():.4f}\")\\n    lossi.append(loss.log10().item())'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":24}],"source":["%%time\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","\n","# Define your custom layers here\n","\n","# Define the model using the custom layers\n","class CustomModel(nn.Module):\n","    def __init__(self, vocab_size, n_embd, n_hidden):\n","        super(CustomModel, self).__init__()\n","        # Create your model architecture using the custom layers\n","        self.model = Sequential([\n","            Embedding(vocab_size, n_embd),\n","            FlattenConsecutive(2), Linear(n_embd * 2, n_hidden, bias=False), BatchNorm1d(n_hidden), Tanh(),\n","            FlattenConsecutive(2), Linear(n_hidden*2, n_hidden, bias=False), BatchNorm1d(n_hidden), Tanh(),\n","            FlattenConsecutive(2), Linear(n_hidden*2, n_hidden, bias=False), BatchNorm1d(n_hidden), Tanh(),\n","            Linear(n_hidden, vocab_size),\n","        ])\n","\n","    def forward(self, x):\n","        return self.model(x)\n","\n","# Initialize the model\n","n_embd = 30\n","n_hidden = 512\n","model = CustomModel(vocab_size, n_embd, n_hidden)\n","\n","# Parameter initialization\n","with torch.no_grad():\n","    model.model.layers[-1].weight *= 0.1  # Last layer make less confident\n","\n","# Move the model to the GPU if available\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"Training on device: {device}\")\n","model.to(device)\n","\n","# Convert data to GPU\n","Xtr = Xtr.to(device)\n","Ytr = Ytr.to(device)\n","\n","# Define the optimizer\n","optimizer = optim.SGD(model.parameters(), lr=0.0001)\n","# Define the L2 regularization strength\n","#weight_decay = 1e-3\n","\n","# Define the optimizer with weight decay (L2 regularization)\n","#optimizer = torch.optim.SGD(model.parameters(), lr=0.001, weight_decay=weight_decay)\n","\n","# Same optimization as last time\n","max_steps = 200000\n","batch_size = 128\n","lossi = []\n","\n","for i in range(max_steps):\n","    # Minibatch construction\n","    ix = torch.randint(0, Xtr.shape[0], (batch_size,), device=device)\n","    Xb, Yb = Xtr[ix], Ytr[ix]  # Batch X,Y\n","\n","    # Forward pass\n","    logits = model(Xb)\n","    loss = F.cross_entropy(logits, Yb)\n","\n","    # Backward pass\n","    optimizer.zero_grad()\n","    loss.backward()\n","\n","    # Update: simple SGD\n","    lr = 0.0001 if i < 150000 else 0.001  # Step learning rate decay\n","    optimizer.step()\n","\n","    # Track stats\n","    if i % 10000 == 0:\n","        print(f\"{i:7d}/{max_steps:7d}: {loss.item():.4f}\")\n","    lossi.append(loss.log10().item())\n","\n","'''for i in range(max_steps):\n","    # Minibatch construction\n","    ix = torch.randint(0, Xtr.shape[0], (batch_size,), device=device)\n","    Xb, Yb = Xtr[ix], Ytr[ix]  # Batch X,Y\n","\n","    # Forward pass\n","    logits = model(Xb)\n","    loss = F.cross_entropy(logits, Yb)\n","\n","    # L2 regularization (weight decay)\n","    l2_regularization = 0.0\n","    for param in model.parameters():\n","        l2_regularization += torch.norm(param, p=2) ** 2\n","\n","    loss += weight_decay * l2_regularization\n","\n","    # Backward pass\n","    optimizer.zero_grad()\n","    loss.backward()\n","\n","    # Update: simple SGD\n","    lr = 0.001 if i < 150000 else 0.01  # Step learning rate decay\n","    optimizer.step()\n","\n","    # Track stats\n","    if i % 10000 == 0:\n","        print(f\"{i:7d}/{max_steps:7d}: {loss.item():.4f}\")\n","    lossi.append(loss.log10().item())'''\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":447},"id":"L3gJYCP26NPe","executionInfo":{"status":"ok","timestamp":1690395566127,"user_tz":-330,"elapsed":1346,"user":{"displayName":"Santosh Bhamidipati","userId":"03330145564595875028"}},"outputId":"13c1822e-8a0d-49d5-8bd5-a780ef90e487"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[<matplotlib.lines.Line2D at 0x7be0f181a530>]"]},"metadata":{},"execution_count":28},{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}],"source":["plt.plot(torch.tensor(lossi).view(-1, 1000).mean(1))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jBu-tBNy6NPf","executionInfo":{"status":"ok","timestamp":1690395566714,"user_tz":-330,"elapsed":3,"user":{"displayName":"Santosh Bhamidipati","userId":"03330145564595875028"}},"outputId":"b7db08d2-880f-4c2c-893c-f837d70cf34e"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["CustomModel(\n","  (model): Sequential(\n","    (layers): ModuleList(\n","      (0): Embedding(\n","        (embedding): Embedding(39, 30)\n","      )\n","      (1): FlattenConsecutive()\n","      (2): Linear()\n","      (3): BatchNorm1d()\n","      (4): Tanh()\n","      (5): FlattenConsecutive()\n","      (6): Linear()\n","      (7): BatchNorm1d()\n","      (8): Tanh()\n","      (9): FlattenConsecutive()\n","      (10): Linear()\n","      (11): BatchNorm1d()\n","      (12): Tanh()\n","      (13): Linear()\n","    )\n","  )\n",")"]},"metadata":{},"execution_count":29}],"source":["model.eval()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"owNwA8D16NPf","executionInfo":{"status":"ok","timestamp":1690395568707,"user_tz":-330,"elapsed":4,"user":{"displayName":"Santosh Bhamidipati","userId":"03330145564595875028"}},"outputId":"a76db213-3e28-4ce9-a29e-8a38e14d0dbe"},"outputs":[{"output_type":"stream","name":"stdout","text":["train 0.4822658598423004\n","val 2.0276665687561035\n"]}],"source":["# evaluate the loss\n","@torch.no_grad() # this decorator disables gradient tracking inside pytorch\n","def split_loss(split):\n","  x,y = {\n","    'train': (Xtr.to(device), Ytr.to(device)),\n","    'val': (Xdev.to(device), Ydev.to(device)),\n","    'test': (Xte.to(device), Yte.to(device)),\n","  }[split]\n","  logits = model(x)\n","  loss = F.cross_entropy(logits, y)\n","  print(split, loss.item())\n","\n","split_loss('train')\n","split_loss('val')"]},{"cell_type":"markdown","metadata":{"id":"6K3iSWl26NPf"},"source":["### performance log\n","\n","- original (3 character context + 200 hidden neurons, 12K params): train 2.058, val 2.105\n","- context: 3 -> 8 (22K params): train 1.918, val 2.027\n","- flat -> hierarchical (22K params): train 1.941, val 2.029\n","- fix bug in batchnorm: train 1.912, val 2.022\n","- scale up the network: n_embd 24, n_hidden 128 (76K params): train 1.769, val 1.993\n"]},{"cell_type":"markdown","metadata":{"id":"rGIQRhdr7OtO"},"source":["## Save Model"]},{"cell_type":"code","source":["# Save the model to a file\n","checkpoint_path = 'model.pth'\n","torch.save(model.state_dict(), checkpoint_path)"],"metadata":{"id":"8UMJYffLW2YK"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1785,"status":"ok","timestamp":1690395586985,"user":{"displayName":"Santosh Bhamidipati","userId":"03330145564595875028"},"user_tz":-330},"id":"CNHLLpPR7mp0","outputId":"1f40f45c-9ef9-4207-ca0f-74b78174c341"},"outputs":[{"output_type":"stream","name":"stdout","text":["ghana,nip,2014,3.01\n","sgarkigt2ur,t4hsri4,tza,2014,8.22\n","camhrd,2014,2.25\n","niswza0,mhy,2014,1.61\n","finland,tun,2014,3.09\n","netuna,yve,2014,3.04\n","rbenin,ben,2014,6.79\n","ningarb,nun,2014,7.45\n","bilevhn,7ss,2014,1.7\n","unitoz ugastan, rz,2014,1.63\n","madedosia,muc,2014,3.01\n","tania,mzu,2014,2967\n","golen,awr,2014,1.61\n","ireland,pol,28143\n","turvsies,urj,2014,1.51\n","kazakr6ua,spa,2014,1.77\n","colomdia,wte,2014,5.26\n","ireunicarls,r4a,2014,4.5b\n","netherlands,ret,2016\n","polane,pod,2014,2.41\n","tolzay,arw,2014,1.21\n","nicaigaroi,ala,27n4,2o8,2014,6.75\n","pain,esu,2014,1.61\n","united kin8dnm,gte,2014,6.76\n","united kingdom,gbr,2014,6.69\n","belgium,bel,2014,1.75\n","kerea,apa,2014,2.81\n","kerbedg7rm,hun,2014,\n","fuswchita6polanda,old,2014,1.79\n","poland,pol,2014,2.26\n","alo\n","aritedis,6hk,2014,1.71\n","unitray,uni,2014,1.61\n","mawy,orm,2014,1.8\n","peru,per,2014,1.77\n","sortoulg3ra,cal,2014,6.22\n","moldajis,edg,201o,3.81\n","honduras,ugd,2014,1.46\n","ma5ana,mdl,2014,1.73\n","pola,4mhl,bgl,2014,1.71\n","nesthhslas,gbn,207za7\n","honduras,unn6anndnanda,alg,2014,1.81\n","pelunder,etun,n.k,2014,1.8\n","norea,anc,2014,208200.49\n","celand,fin,2014,1.73\n","pakistan,pak,2014,1462y,m014.7.21\n","tolania,som,2014,5.2x\n","benitey,muu,2014,1782\n","guatemhla,2s1370.de1,kra,2014,6.14\n","cagabel,ne1,6e14,1013,3.\n"]}],"source":["# Assuming you have loaded the model as shown in the previous response\n","# and put it into evaluation mode using model.eval()\n","\n","# Sample from the model\n","for _ in range(50):\n","    out = []\n","    context = [0] * block_size  # initialize with all ...\n","\n","    with torch.no_grad():\n","        while True:\n","            # Convert the context to a tensor and transfer it to the device\n","            context_tensor = torch.tensor([context])\n","            context_tensor = context_tensor.to(device)  # Assuming 'device' is properly defined\n","\n","            # Forward pass the neural net\n","            logits = model(context_tensor)\n","            probs = F.softmax(logits, dim=1)\n","\n","            # Sample from the distribution\n","            ix = torch.multinomial(probs, num_samples=1).item()\n","\n","            # Shift the context window and track the samples\n","            context = context[1:] + [ix]\n","            out.append(ix)\n","\n","            # If we sample the special '.' token, break\n","            if ix == 0:\n","                break\n","\n","    generated_text = ''.join(itos[i] for i in out)  # Decode the generated word\n","    #print(len(set(out)))\n","    print(generated_text.replace(\"*\",\"\"))  # Print the generated text for each iteration\n"]},{"cell_type":"markdown","metadata":{"id":"W_FwKCW_-pg9"},"source":["\n","## load the saved model"]},{"cell_type":"code","source":["%pip install dill\n","import dill\n","\n","# Save the model using dill.dump\n","with open('model.pkl', 'wb') as f:\n","    dill.dump(model, f)\n","\n","# Load the model using dill.load\n","with open('model.pkl', 'rb') as f:\n","    loaded_model = dill.load(f)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"W_n8tqpYVqxh","executionInfo":{"status":"ok","timestamp":1690397206875,"user_tz":-330,"elapsed":6066,"user":{"displayName":"Santosh Bhamidipati","userId":"03330145564595875028"}},"outputId":"8f1487b0-21f3-4fcc-9d9c-2ebe33562d97"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting dill\n","  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: dill\n","Successfully installed dill-0.3.7\n"]}]},{"cell_type":"code","source":["loaded_model.state_dict()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eAOfcp_Re-g_","executionInfo":{"status":"ok","timestamp":1690397242023,"user_tz":-330,"elapsed":1177,"user":{"displayName":"Santosh Bhamidipati","userId":"03330145564595875028"}},"outputId":"e62b92dc-e5f4-4b90-853f-1664d21ef34d"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["OrderedDict([('model.layers.0.embedding.weight',\n","              tensor([[ 1.9180,  1.4933,  0.9032,  ...,  1.3291, -0.2335,  0.0390],\n","                      [-0.2504,  0.8603, -1.3828,  ...,  0.0356, -0.0647,  0.6762],\n","                      [-0.1015,  1.8573, -1.1953,  ...,  0.0551,  0.7472, -0.4910],\n","                      ...,\n","                      [ 1.1901,  1.4109,  0.7956,  ..., -0.7785, -0.4175,  1.1048],\n","                      [ 0.2514, -0.1120,  0.7708,  ..., -0.4358, -0.0149,  0.5450],\n","                      [ 0.1230, -0.8732,  1.2215,  ...,  1.0107, -0.6509,  1.4622]],\n","                     device='cuda:0')),\n","             ('model.layers.2.weight',\n","              tensor([[ 0.1197,  0.1037,  0.0253,  ...,  0.1514, -0.0193, -0.1821],\n","                      [ 0.1055, -0.1113, -0.0813,  ..., -0.2518, -0.2264,  0.0434],\n","                      [-0.1263, -0.0099,  0.0871,  ..., -0.0185, -0.0673, -0.1473],\n","                      ...,\n","                      [-0.0059, -0.0127, -0.0804,  ...,  0.0885, -0.0920,  0.2325],\n","                      [ 0.0082, -0.1353,  0.0167,  ..., -0.1899,  0.2133,  0.1047],\n","                      [-0.0682, -0.0854, -0.0161,  ..., -0.1589, -0.2176, -0.0136]],\n","                     device='cuda:0')),\n","             ('model.layers.3.gamma',\n","              tensor([1.0003, 0.9987, 1.0015, 0.9980, 1.0014, 1.0009, 1.0007, 1.0003, 1.0019,\n","                      0.9985, 0.9992, 1.0044, 0.9989, 0.9983, 1.0018, 1.0010, 0.9995, 1.0032,\n","                      1.0030, 1.0002, 1.0022, 1.0004, 0.9981, 1.0005, 1.0009, 1.0003, 1.0011,\n","                      1.0006, 0.9986, 0.9992, 1.0007, 1.0017, 0.9983, 1.0011, 0.9988, 0.9987,\n","                      1.0048, 1.0009, 1.0031, 1.0000, 1.0026, 1.0009, 1.0021, 1.0032, 1.0000,\n","                      0.9996, 1.0006, 0.9988, 1.0003, 0.9993, 0.9999, 1.0015, 1.0030, 0.9998,\n","                      0.9987, 1.0017, 0.9989, 1.0018, 1.0011, 1.0010, 1.0012, 0.9968, 0.9995,\n","                      1.0021, 1.0018, 1.0008, 0.9991, 0.9995, 0.9964, 1.0013, 0.9939, 0.9983,\n","                      1.0005, 0.9995, 0.9991, 1.0025, 1.0020, 0.9995, 1.0005, 1.0016, 0.9997,\n","                      0.9989, 0.9976, 1.0019, 1.0005, 1.0020, 1.0011, 0.9999, 1.0012, 0.9982,\n","                      0.9998, 0.9995, 1.0009, 0.9984, 0.9968, 1.0013, 1.0034, 1.0018, 0.9998,\n","                      0.9983, 1.0024, 1.0001, 0.9996, 1.0047, 0.9993, 0.9991, 1.0025, 1.0017,\n","                      1.0009, 0.9971, 1.0027, 0.9988, 1.0044, 0.9998, 1.0053, 0.9995, 0.9991,\n","                      0.9995, 1.0042, 1.0060, 1.0011, 1.0047, 1.0013, 1.0012, 0.9995, 0.9988,\n","                      0.9986, 1.0009, 1.0046, 1.0033, 1.0004, 1.0019, 0.9979, 0.9985, 1.0017,\n","                      0.9999, 1.0017, 1.0008, 0.9978, 0.9989, 1.0000, 1.0003, 0.9997, 0.9993,\n","                      1.0013, 1.0004, 1.0000, 1.0000, 1.0007, 0.9974, 0.9999, 0.9996, 1.0006,\n","                      0.9980, 0.9999, 0.9995, 0.9991, 1.0005, 1.0031, 1.0009, 0.9994, 1.0009,\n","                      0.9989, 1.0004, 0.9984, 0.9997, 1.0001, 0.9981, 1.0031, 1.0028, 0.9982,\n","                      0.9996, 1.0053, 1.0006, 1.0018, 1.0037, 0.9992, 0.9991, 1.0034, 0.9997,\n","                      1.0002, 0.9992, 1.0001, 0.9996, 0.9990, 1.0002, 0.9980, 1.0000, 0.9994,\n","                      1.0009, 1.0037, 0.9992, 1.0028, 0.9993, 1.0000, 1.0064, 1.0006, 1.0001,\n","                      0.9991, 0.9992, 1.0009, 1.0002, 0.9997, 0.9981, 1.0008, 0.9993, 0.9993,\n","                      0.9980, 0.9992, 0.9982, 1.0001, 0.9998, 1.0008, 1.0008, 0.9993, 1.0005,\n","                      0.9995, 1.0012, 1.0032, 1.0004, 1.0008, 0.9988, 1.0001, 0.9995, 0.9977,\n","                      1.0039, 1.0024, 1.0007, 0.9992, 0.9984, 1.0011, 0.9987, 0.9993, 0.9992,\n","                      0.9980, 1.0016, 1.0011, 1.0005, 0.9998, 1.0017, 0.9984, 0.9998, 0.9996,\n","                      1.0035, 0.9999, 0.9995, 1.0047, 0.9997, 1.0003, 1.0029, 1.0012, 0.9984,\n","                      1.0010, 0.9996, 0.9968, 0.9995, 1.0002, 1.0002, 0.9992, 0.9976, 0.9973,\n","                      1.0010, 1.0010, 1.0005, 1.0003, 0.9990, 1.0001, 0.9980, 1.0049, 1.0044,\n","                      1.0018, 1.0017, 0.9971, 1.0012, 0.9999, 1.0011, 0.9992, 1.0015, 1.0029,\n","                      0.9990, 1.0017, 0.9985, 1.0017, 1.0015, 1.0020, 1.0001, 0.9998, 1.0011,\n","                      1.0048, 1.0019, 0.9997, 0.9965, 1.0016, 0.9988, 0.9989, 1.0003, 1.0027,\n","                      0.9991, 1.0020, 1.0007, 1.0056, 1.0017, 1.0013, 0.9998, 1.0018, 1.0015,\n","                      1.0002, 0.9995, 1.0001, 0.9999, 0.9980, 1.0021, 0.9989, 0.9979, 1.0013,\n","                      1.0007, 0.9986, 0.9986, 0.9979, 1.0023, 1.0007, 1.0016, 1.0036, 1.0014,\n","                      1.0002, 1.0007, 0.9984, 0.9969, 1.0004, 0.9989, 0.9990, 1.0022, 1.0001,\n","                      0.9951, 1.0004, 1.0025, 1.0017, 0.9990, 1.0002, 1.0066, 1.0002, 1.0027,\n","                      1.0032, 1.0036, 0.9990, 1.0010, 0.9997, 1.0013, 0.9995, 1.0021, 1.0016,\n","                      0.9997, 0.9990, 0.9997, 0.9991, 0.9991, 1.0052, 0.9991, 1.0026, 0.9971,\n","                      1.0035, 0.9979, 1.0015, 1.0007, 0.9999, 1.0004, 1.0009, 0.9994, 0.9989,\n","                      1.0026, 0.9994, 1.0011, 0.9965, 1.0007, 1.0002, 1.0010, 0.9986, 0.9977,\n","                      0.9976, 1.0015, 0.9972, 0.9973, 1.0018, 1.0006, 1.0027, 1.0017, 1.0012,\n","                      0.9998, 1.0011, 1.0008, 1.0030, 1.0008, 1.0031, 1.0021, 1.0024, 1.0011,\n","                      0.9998, 0.9993, 0.9981, 0.9994, 0.9998, 1.0034, 0.9993, 1.0000, 0.9993,\n","                      1.0005, 1.0007, 1.0037, 1.0025, 1.0052, 0.9981, 1.0006, 1.0029, 0.9985,\n","                      0.9965, 0.9984, 1.0012, 1.0005, 1.0000, 1.0043, 1.0030, 0.9995, 1.0013,\n","                      1.0001, 0.9969, 0.9984, 0.9966, 1.0033, 1.0014, 1.0005, 0.9998, 1.0021,\n","                      0.9967, 0.9968, 1.0001, 1.0009, 1.0014, 1.0031, 0.9960, 0.9995, 1.0006,\n","                      0.9989, 1.0002, 1.0011, 0.9982, 1.0008, 0.9969, 1.0009, 0.9987, 1.0010,\n","                      1.0009, 1.0041, 1.0017, 1.0001, 0.9984, 1.0022, 1.0005, 0.9999, 0.9988,\n","                      1.0024, 1.0013, 1.0003, 1.0056, 0.9982, 1.0011, 0.9990, 1.0033, 1.0000,\n","                      1.0006, 0.9994, 0.9999, 1.0009, 0.9970, 1.0024, 0.9974, 0.9979, 1.0020,\n","                      1.0009, 1.0019, 1.0003, 1.0031, 0.9990, 1.0006, 1.0022, 0.9987, 1.0024,\n","                      1.0010, 1.0034, 0.9995, 1.0045, 0.9999, 1.0019, 1.0006, 1.0012, 0.9985,\n","                      0.9993, 0.9987, 1.0016, 1.0008, 0.9978, 0.9997, 0.9995, 0.9996, 1.0000,\n","                      0.9980, 1.0018, 0.9973, 1.0018, 1.0000, 1.0031, 1.0004, 1.0053],\n","                     device='cuda:0')),\n","             ('model.layers.3.beta',\n","              tensor([-1.2951e-03,  6.8062e-04,  3.0405e-03, -1.1754e-03, -8.5383e-04,\n","                      -1.8753e-03, -7.0640e-04,  5.3026e-03, -3.2989e-03, -9.4405e-04,\n","                      -6.5098e-05,  1.2384e-03,  1.7953e-03, -3.1308e-03, -2.3773e-03,\n","                       6.1285e-04, -5.1640e-04,  8.1547e-04,  2.7178e-04, -4.5584e-03,\n","                      -7.3571e-04,  5.7187e-04, -8.8801e-04, -1.0664e-04,  2.1276e-04,\n","                       1.4966e-04,  1.0822e-03,  5.7045e-05,  9.1610e-04, -2.8666e-03,\n","                       1.9552e-03,  7.0564e-04, -1.6562e-03,  1.7795e-03, -9.1965e-04,\n","                      -1.9279e-03, -8.4114e-04, -1.5212e-03,  2.2374e-03, -1.9605e-03,\n","                       6.9475e-04, -2.1302e-03,  1.6856e-03, -2.6208e-03,  3.2130e-03,\n","                       8.6505e-04, -4.7390e-03,  9.8396e-04, -2.1700e-03,  5.5319e-03,\n","                       1.2230e-03, -1.0583e-03,  8.9378e-04,  1.4044e-03, -1.0450e-03,\n","                       1.6268e-03, -3.3654e-03,  7.0073e-04, -1.7574e-03, -1.7251e-03,\n","                      -9.2409e-04, -2.5417e-03,  5.4442e-05, -5.5587e-04,  2.8459e-04,\n","                      -1.6824e-03, -1.4286e-03, -2.0133e-03, -3.1441e-05,  1.7244e-03,\n","                      -4.4073e-03, -4.9242e-03,  5.5098e-04,  2.9060e-03, -2.8527e-03,\n","                       2.5656e-03, -2.9593e-03,  1.8136e-03,  2.2287e-03,  2.5315e-03,\n","                       4.8756e-03,  2.2103e-03,  2.8273e-03, -3.7100e-04,  2.4845e-03,\n","                       4.0478e-04, -9.6745e-05,  9.4877e-04, -5.6017e-04, -6.1548e-03,\n","                       2.8367e-03, -1.7359e-03, -3.3403e-04, -9.6179e-04,  1.2557e-03,\n","                       1.4990e-03,  2.4335e-03, -2.6682e-03,  2.8592e-04,  1.6532e-03,\n","                      -5.8862e-03, -9.8291e-04,  1.6478e-03, -2.8422e-03, -2.9480e-04,\n","                      -2.9717e-03,  2.8414e-03, -1.3023e-03, -5.0225e-04, -2.5820e-03,\n","                       2.0870e-03, -1.4234e-03, -2.9499e-03,  2.3050e-03, -5.6134e-04,\n","                       2.0677e-03, -1.8306e-03,  5.8101e-05, -5.8408e-04, -2.8192e-03,\n","                       7.3924e-04,  4.9650e-03, -2.2263e-03,  1.9465e-03, -2.6096e-03,\n","                      -6.7172e-04, -3.5645e-04, -2.0199e-03,  1.1002e-03,  1.3529e-03,\n","                       2.4026e-03,  1.0313e-03,  2.5587e-03,  1.8935e-03, -2.9719e-03,\n","                      -2.0672e-03,  1.6807e-03,  4.2873e-04, -5.1421e-03,  2.4256e-04,\n","                       2.8432e-04,  8.5627e-04,  1.5946e-03,  2.0956e-03,  1.1708e-03,\n","                       2.5701e-03, -4.9165e-04, -1.1869e-03, -1.7840e-03, -8.6738e-04,\n","                       1.0372e-04, -1.0651e-03,  1.2592e-04, -3.9956e-03,  9.0231e-06,\n","                       1.3960e-05,  5.5743e-03, -1.4642e-03, -1.9676e-03, -3.1745e-03,\n","                      -4.4280e-03, -1.7504e-03,  2.1455e-03,  2.8294e-03, -1.4660e-03,\n","                      -3.7126e-03, -1.4472e-03, -1.4743e-03,  1.4027e-03,  2.4090e-03,\n","                      -1.6032e-04,  1.6178e-03,  6.4515e-05, -1.7500e-03, -4.5409e-03,\n","                      -4.6352e-03, -1.2254e-03,  1.1336e-03,  1.2351e-03, -1.0679e-03,\n","                       3.5940e-03,  2.7622e-04, -4.9996e-04, -3.2002e-03, -1.5262e-03,\n","                       1.6858e-03,  8.1800e-04, -6.8221e-04,  3.1375e-04, -1.1228e-03,\n","                      -1.9287e-03,  6.7319e-04,  4.0765e-03,  1.8313e-03, -7.8019e-05,\n","                      -3.1763e-03,  3.4986e-03, -2.6210e-03, -1.0979e-03, -1.2671e-03,\n","                       1.7798e-03, -2.6179e-04, -8.4180e-05, -2.4955e-03, -1.0707e-03,\n","                      -3.2528e-04, -8.1978e-04, -1.2342e-03,  3.9028e-03, -1.0822e-03,\n","                       4.4951e-04,  1.8942e-03, -1.5576e-03,  1.6390e-03,  3.5194e-03,\n","                      -3.1024e-03, -2.3144e-04, -2.6395e-03, -1.0459e-03,  3.5544e-04,\n","                       3.9650e-03, -1.9421e-03, -1.4462e-03,  1.4962e-03, -1.4353e-03,\n","                      -7.0118e-04,  6.4579e-04, -1.1354e-03, -5.1080e-03,  2.2783e-03,\n","                       5.2306e-04, -1.1550e-04, -9.1448e-05, -3.6141e-03, -1.7381e-03,\n","                      -8.1082e-04, -1.5729e-03,  3.5361e-03, -2.0881e-03,  7.1987e-04,\n","                       7.5957e-04,  2.3882e-04,  5.5406e-04,  2.7780e-03,  3.5273e-03,\n","                       8.1438e-04,  2.2520e-04,  1.2697e-03, -7.1340e-04,  1.4171e-03,\n","                      -2.2660e-03,  6.7623e-03, -2.6794e-03, -2.2799e-03,  1.3730e-04,\n","                       2.3764e-04, -3.5600e-04, -1.7813e-04, -3.8968e-03,  2.0809e-03,\n","                      -3.3787e-03, -1.8542e-03,  2.4978e-03, -2.1634e-03, -4.6453e-03,\n","                      -2.5277e-03,  1.2578e-03,  2.9402e-04, -2.2386e-03,  1.3690e-03,\n","                      -2.4594e-03, -1.2148e-03,  3.1040e-03, -2.8477e-03,  1.7143e-03,\n","                       2.0983e-03, -6.9328e-04, -4.5459e-04, -7.6924e-04,  1.4357e-04,\n","                       1.9559e-03,  7.0541e-04, -2.2361e-03,  2.2925e-03,  1.7310e-03,\n","                      -8.2231e-04, -5.0701e-04,  1.3534e-03,  7.8329e-04, -5.2868e-04,\n","                       1.5725e-03, -4.3350e-03,  8.9378e-04,  1.8071e-03,  1.2934e-03,\n","                      -1.2558e-03, -2.5714e-03,  2.5871e-03,  1.9330e-03,  5.7633e-04,\n","                      -1.0303e-03, -1.9653e-03, -1.2963e-03,  1.7336e-04,  1.1452e-03,\n","                      -6.3306e-05, -3.2206e-03,  5.6266e-03, -9.4957e-04,  1.2764e-03,\n","                       2.2257e-04, -1.7489e-03,  3.5449e-03, -2.9165e-03, -3.5235e-03,\n","                       2.4254e-03, -2.4772e-05,  1.4361e-03, -1.3292e-03, -7.7153e-05,\n","                      -1.7835e-03, -2.7720e-04, -1.5244e-03,  2.0260e-03,  7.1837e-04,\n","                      -2.2921e-04,  1.4363e-03,  2.8267e-04, -2.0800e-03,  7.3589e-04,\n","                       1.0857e-03,  6.5346e-04, -7.8839e-04,  1.7717e-03,  4.0878e-04,\n","                      -7.3426e-04,  4.8594e-04,  3.9266e-03,  5.4488e-04, -2.4148e-04,\n","                       2.2440e-03,  2.2263e-03,  5.3285e-04,  1.2052e-03, -2.3164e-03,\n","                       8.1783e-04, -6.7039e-05, -5.0489e-04, -6.9227e-04, -3.6818e-03,\n","                      -5.6755e-04,  3.4024e-03, -7.7832e-04,  7.8921e-04,  7.2624e-04,\n","                      -4.5174e-03, -5.5995e-04, -4.4215e-03,  5.7814e-04,  6.8971e-04,\n","                       4.9428e-04,  9.6821e-04, -1.8905e-03, -7.3687e-03, -2.6060e-03,\n","                       5.8845e-04,  1.7755e-03,  1.1347e-03,  1.4279e-03, -3.0382e-03,\n","                       7.8602e-04,  3.7739e-03,  6.1551e-04,  2.2269e-03, -1.5385e-03,\n","                       5.2252e-04, -5.6719e-03, -3.6767e-03, -1.0533e-03, -8.1003e-04,\n","                       8.9959e-04,  1.4329e-03,  2.6990e-03,  1.4662e-03,  6.4537e-04,\n","                      -2.6826e-03,  8.3223e-04,  6.5579e-04,  1.0026e-03, -9.2457e-04,\n","                       2.9318e-03,  3.2440e-03, -1.5036e-03,  2.6420e-03,  2.8328e-03,\n","                       4.5782e-04, -2.3383e-03, -4.0805e-04, -3.9915e-03, -1.0946e-03,\n","                       7.5243e-04,  3.6524e-03,  6.8171e-04, -2.3213e-04,  9.6893e-04,\n","                       3.8851e-03,  1.1790e-03, -4.2209e-03, -4.1425e-03, -1.9651e-03,\n","                       2.2943e-03, -3.1427e-04, -1.8834e-04, -2.1233e-04,  2.3454e-04,\n","                      -6.8398e-04, -1.0177e-03, -1.9663e-04,  5.1918e-03,  1.2967e-03,\n","                       1.7878e-03,  2.0416e-04,  1.0205e-04, -2.8139e-03,  8.1367e-04,\n","                       2.0734e-03, -7.1788e-04,  1.6877e-03,  5.5874e-04, -2.8783e-03,\n","                       3.3353e-03, -1.1272e-03,  3.5306e-03,  3.1003e-04,  1.4104e-03,\n","                      -1.0710e-03,  5.0702e-03,  1.6301e-03, -2.3500e-03, -1.5524e-03,\n","                      -2.8177e-03,  2.3501e-03, -4.5929e-03, -1.1152e-03, -1.2397e-03,\n","                      -3.1031e-03,  2.3936e-03, -2.6347e-03, -2.0958e-03, -1.2035e-03,\n","                       4.9397e-03, -6.1505e-04,  4.7699e-04,  1.3266e-03,  1.3108e-03,\n","                       2.4258e-04, -2.6028e-03,  1.4185e-03, -1.4930e-03, -1.4411e-03,\n","                       1.5348e-03,  2.0339e-03,  8.9484e-04, -2.1712e-04, -3.4790e-03,\n","                      -1.6788e-03, -1.5735e-03,  1.4632e-03,  1.0183e-03, -4.6826e-03,\n","                       3.6709e-03, -1.5212e-03, -1.7668e-03, -8.9771e-05,  3.0157e-03,\n","                       3.4509e-04, -3.6726e-03,  1.5487e-03,  2.6637e-03,  2.7764e-03,\n","                      -1.0996e-03, -1.9260e-04,  2.0803e-03,  2.4174e-03, -8.9108e-05,\n","                       2.6781e-05, -2.0394e-03,  2.6731e-03, -1.8263e-04,  6.9634e-04,\n","                      -2.6892e-03,  9.3922e-04, -3.0080e-03,  2.3145e-03,  1.0122e-03,\n","                       2.1914e-04,  2.2300e-03,  1.9432e-03, -6.0681e-04, -7.7652e-04,\n","                      -1.7099e-03,  2.0107e-03,  1.8844e-03,  1.4735e-03, -1.6957e-03,\n","                      -6.5290e-03, -2.4290e-03,  1.6995e-03,  3.3857e-03,  1.5573e-03,\n","                       3.2540e-03, -1.0520e-03], device='cuda:0')),\n","             ('model.layers.3.running_mean',\n","              tensor([[[ 3.1262e-02, -1.4576e-02,  1.5414e-01,  3.8182e-01, -2.7011e-02,\n","                        -4.4985e-01, -5.3786e-02, -2.3252e-01,  2.5096e-01, -1.9782e-01,\n","                        -1.2222e-01,  1.9895e-01, -1.8944e-01, -5.1314e-02, -2.0369e-01,\n","                         5.4382e-01,  1.9458e-01, -1.5533e-01,  1.3162e-01, -1.8240e-01,\n","                        -1.3753e-01,  1.8159e-01, -2.9118e-01, -1.9636e-01, -2.3569e-01,\n","                         2.8558e-01, -3.5538e-01,  2.9764e-03,  2.5973e-01,  2.2055e-01,\n","                        -2.9022e-01,  1.6681e-01,  8.2740e-02, -2.1281e-01, -1.9627e-02,\n","                         4.3717e-02, -4.4412e-01,  1.2063e-01, -3.4479e-01,  3.3618e-01,\n","                        -3.7673e-01,  3.5706e-01, -4.5253e-04,  6.6406e-02,  1.5566e-01,\n","                         4.7579e-02, -5.4534e-01, -4.2365e-01,  3.2857e-01, -4.4437e-01,\n","                        -7.6203e-02, -1.6274e-01,  1.7767e-01, -2.1258e-01,  1.2198e-01,\n","                        -1.0653e-01,  1.4672e-01, -2.7502e-01,  2.4554e-02, -6.5379e-01,\n","                         4.8485e-03,  1.6225e-01,  1.2232e-01,  4.1640e-01, -3.6300e-01,\n","                        -9.6142e-02, -4.0207e-01, -1.7543e-01,  1.4131e-01, -1.4929e-01,\n","                        -1.0090e-01, -1.9014e-01, -9.9074e-02, -7.3121e-02,  1.2233e-01,\n","                        -2.1013e-01, -5.2332e-01, -1.5121e-01, -6.4268e-02, -2.0724e-01,\n","                         1.2785e-01,  3.0797e-01,  1.2310e-01,  3.4307e-01,  6.4369e-02,\n","                         2.0203e-01, -3.9408e-01,  4.9032e-02, -2.6011e-01, -1.7211e-02,\n","                        -3.9718e-01, -2.1881e-02,  2.7303e-02,  3.7380e-01,  4.2184e-01,\n","                         2.2103e-02,  4.8762e-01,  3.8579e-01, -2.8904e-01,  1.4185e-01,\n","                        -5.8344e-02, -1.6950e-01, -2.5927e-01,  1.0943e-01,  6.9907e-01,\n","                        -3.0329e-02,  2.9566e-01, -2.9360e-02,  2.3412e-01, -4.3962e-01,\n","                         8.1920e-02, -2.9656e-02,  6.2166e-01,  3.7206e-01, -1.3863e-01,\n","                         2.3442e-01, -4.7062e-01,  5.3738e-02,  1.2113e-01, -4.1512e-01,\n","                        -1.7471e-01, -1.6503e-01,  5.0481e-01, -8.0021e-02, -7.1307e-01,\n","                        -7.6657e-02, -1.7545e-01, -1.0488e-01,  1.3809e-01,  4.4018e-01,\n","                         6.3463e-02, -2.7313e-01, -2.8846e-02,  3.7757e-01,  3.1943e-01,\n","                        -1.4809e-01, -1.5676e-01, -4.6423e-01,  5.1656e-01, -3.5922e-01,\n","                         6.3326e-02,  4.4207e-01, -1.6530e-01, -1.1027e-01,  8.7612e-02,\n","                         2.8351e-01,  1.2019e-01, -1.9540e-01,  2.6747e-01,  1.1714e-01,\n","                        -1.8001e-01, -5.7597e-02, -3.2280e-01,  2.6327e-01,  3.5703e-01,\n","                        -4.0598e-02, -5.8141e-02,  2.5354e-01, -3.9522e-02,  9.0592e-02,\n","                         3.0989e-01, -1.6877e-01, -2.5392e-01,  2.3671e-01,  3.0292e-01,\n","                         2.3766e-01,  3.0862e-01, -6.1219e-02,  3.6286e-01, -4.2567e-01,\n","                         5.5167e-01,  5.0601e-01,  3.8973e-02, -5.4610e-02, -3.8521e-02,\n","                        -2.2182e-02, -2.7051e-03, -1.4356e-02, -2.6015e-01, -3.2057e-01,\n","                         1.1712e-01, -2.7163e-01, -2.2215e-01,  5.2772e-01,  2.3882e-02,\n","                         3.8925e-01,  1.1979e-03,  1.5815e-02,  1.0295e-01,  3.5815e-01,\n","                         4.7808e-01, -3.2094e-01, -2.2309e-01, -2.6122e-02, -1.4153e-01,\n","                         1.8500e-01,  5.3814e-01,  7.9409e-02,  3.4814e-01, -5.9958e-01,\n","                        -2.0308e-01,  2.6937e-01,  3.8041e-01,  4.6209e-02,  3.2745e-01,\n","                         1.4965e-01,  1.6127e-01, -1.2454e-01,  5.1002e-02, -3.3285e-01,\n","                        -3.3567e-01,  3.0825e-02,  3.3108e-01,  2.9430e-01, -4.5857e-01,\n","                         5.1632e-01, -1.0095e-01,  3.2334e-01,  1.5996e-01, -1.7367e-01,\n","                         3.7766e-01,  1.9324e-02,  2.0738e-02,  7.8588e-02, -1.7476e-01,\n","                        -1.1858e-02, -1.0574e-01,  1.8886e-01,  4.6015e-01,  3.4758e-01,\n","                        -1.5164e-01,  4.5688e-01,  1.8612e-01,  1.5284e-01,  3.5713e-02,\n","                         3.2050e-03,  8.7273e-02, -4.8693e-02, -1.3580e-01,  4.0484e-01,\n","                         1.7421e-01,  6.3722e-02,  5.6430e-01, -1.2251e-01,  1.1528e-01,\n","                        -1.8645e-01,  5.3644e-03, -4.9567e-01, -2.5631e-01, -5.2021e-01,\n","                         1.9247e-01,  3.4584e-01,  3.0056e-01, -5.2272e-01,  6.0014e-02,\n","                        -8.6714e-02,  2.9397e-01,  8.3854e-02,  3.2492e-01, -2.1762e-01,\n","                        -3.1144e-03,  2.4605e-01,  2.3627e-01,  2.4931e-01, -1.7901e-01,\n","                        -3.1574e-01, -2.6360e-01,  4.3776e-01,  8.6284e-02,  5.0956e-02,\n","                         3.8217e-01, -7.6598e-02,  8.6271e-02, -9.5229e-02,  1.0068e-01,\n","                        -7.7817e-03, -1.1667e-01,  4.2394e-01, -1.8308e-02, -4.4320e-01,\n","                        -8.5972e-02,  8.0352e-02, -1.0744e-01, -1.1951e-01,  1.4597e-01,\n","                        -1.9478e-02, -3.5667e-01, -1.4650e-01,  2.6728e-01,  2.5532e-01,\n","                        -2.6106e-01, -2.1227e-01, -1.4736e-03, -2.3380e-01,  1.0729e-01,\n","                         3.4420e-01, -2.4748e-02, -2.9016e-01, -1.5065e-02,  3.0885e-01,\n","                        -2.6264e-01,  2.1283e-02, -1.3197e-01,  3.6766e-01, -3.8718e-01,\n","                        -3.5239e-01,  2.9187e-01,  1.3283e-01,  3.5919e-03, -1.0207e-01,\n","                        -1.0699e-01,  1.2218e-01, -1.3844e-01, -5.0760e-02, -2.1246e-03,\n","                         1.5951e-01, -2.6275e-01,  7.6464e-02,  1.8369e-01,  2.2274e-01,\n","                        -1.7469e-01,  1.8746e-01,  4.5178e-02,  1.0109e-01,  2.8754e-01,\n","                        -4.8359e-01,  1.7717e-01, -3.5706e-02,  2.8649e-01,  2.5968e-01,\n","                        -3.6565e-01, -2.8203e-01, -2.2221e-01,  3.0879e-01, -1.4417e-01,\n","                         2.2028e-01, -4.6129e-02,  2.4851e-04, -1.9030e-02,  9.4794e-02,\n","                        -1.8380e-01,  4.2224e-01,  1.8199e-01,  4.0135e-03, -4.3285e-02,\n","                        -3.9992e-02, -4.9212e-02,  2.4297e-02, -6.3443e-01,  3.0817e-01,\n","                        -1.0885e-01,  1.7825e-01, -4.8445e-02,  4.0574e-01, -6.9618e-03,\n","                        -1.6610e-01,  6.9886e-02, -1.0392e-01,  3.8955e-01, -9.3899e-03,\n","                        -1.3565e-01, -1.2283e-01, -1.8751e-01, -1.6744e-01, -2.2471e-01,\n","                         2.4945e-01,  1.4578e-01,  5.5030e-01, -1.5593e-01,  2.5778e-01,\n","                        -8.0028e-01, -3.5677e-01, -2.1983e-01,  7.1478e-02, -2.7641e-01,\n","                        -6.9063e-01,  5.0402e-01,  6.0497e-01, -5.2097e-01, -4.1026e-01,\n","                        -5.0582e-01,  1.7574e-01, -2.2735e-04, -6.5872e-02, -1.9186e-01,\n","                        -6.5546e-02, -4.7118e-01, -5.1126e-02, -2.6008e-02, -1.9974e-02,\n","                        -1.4930e-01, -2.8600e-01, -2.2820e-01, -3.4618e-01,  2.3690e-02,\n","                         1.6886e-01,  2.4554e-01, -1.1694e-01, -7.6486e-02,  3.9227e-01,\n","                        -1.5705e-01,  3.3083e-02,  3.8772e-02,  4.5431e-01,  2.1155e-01,\n","                        -3.4760e-01, -5.2468e-02,  7.9690e-02, -7.1854e-02,  3.4273e-01,\n","                         3.1648e-01, -2.9939e-01, -8.2214e-02, -1.9060e-01, -4.9718e-03,\n","                         1.3419e-01,  3.8745e-01, -2.9525e-01, -3.0549e-01, -1.6599e-01,\n","                         5.2196e-02, -3.4223e-02, -1.5446e-01, -5.0287e-02,  1.6413e-01,\n","                        -5.5417e-02, -4.0863e-01,  3.1819e-01,  2.4328e-01, -3.2580e-02,\n","                        -2.0409e-01, -5.1115e-02, -4.4807e-01, -2.9091e-01, -1.7408e-01,\n","                         5.0063e-01, -1.6145e-01,  4.5531e-01,  2.0475e-02, -9.5235e-02,\n","                        -8.0207e-03, -6.5814e-02, -6.2046e-02,  3.2935e-01, -8.8888e-01,\n","                        -3.0859e-01,  7.7026e-02,  3.5222e-01,  3.1836e-02,  9.9025e-02,\n","                         2.0362e-01,  2.2449e-01, -2.0842e-01,  1.2941e-01, -1.1143e-01,\n","                         1.8241e-01,  9.9338e-02,  1.4398e-01, -3.0815e-01,  1.5662e-01,\n","                         1.9106e-02,  2.0249e-01, -1.6418e-01,  2.0026e-02, -1.4151e-01,\n","                        -2.5188e-01,  3.1389e-01, -5.5352e-02,  2.3479e-01, -3.5501e-01,\n","                        -1.1128e-02,  5.2363e-01, -2.5998e-01,  2.1997e-01,  5.2294e-02,\n","                        -2.1425e-01,  4.1353e-01,  2.3119e-01, -2.3024e-01,  1.4925e-02,\n","                         2.6396e-02, -3.2571e-01, -8.0195e-01, -2.3513e-01,  1.3157e-01,\n","                        -5.6032e-01, -1.5099e-01, -2.1032e-01,  8.9082e-02,  6.1004e-03,\n","                         2.9074e-01,  8.7848e-02,  1.4887e-01,  1.6356e-01, -2.8028e-01,\n","                        -1.2198e-02,  6.5480e-01, -9.0905e-02,  9.1826e-02,  3.6268e-01,\n","                         2.7843e-01, -1.0085e-01, -5.0083e-01,  2.1518e-01,  2.9065e-01,\n","                         1.6492e-01,  6.0942e-02,  1.6766e-01,  1.9838e-01, -2.8521e-01,\n","                        -4.9155e-01, -1.4387e-01]]], device='cuda:0')),\n","             ('model.layers.3.running_var',\n","              tensor([[[0.6877, 1.0401, 0.9261, 0.8169, 0.4589, 0.8625, 1.0717, 0.5892,\n","                        0.8497, 1.3612, 0.9085, 0.8966, 1.7864, 1.1015, 0.8941, 0.8655,\n","                        1.2136, 0.4501, 1.7249, 1.0553, 0.7273, 0.8862, 2.2810, 0.6104,\n","                        2.6314, 1.1198, 1.7663, 0.7986, 0.4597, 1.0908, 0.7961, 0.6962,\n","                        0.9009, 0.8817, 0.5797, 1.0245, 0.9665, 0.8457, 0.7399, 1.4858,\n","                        0.6889, 1.8820, 1.4592, 0.8118, 0.9463, 0.9198, 1.3373, 1.2858,\n","                        0.5664, 1.7835, 1.9658, 1.3050, 0.4833, 1.2326, 0.7964, 0.8083,\n","                        0.7690, 1.8307, 0.7608, 1.8668, 0.9642, 0.8348, 0.8640, 0.6590,\n","                        0.8306, 1.5588, 0.7560, 0.5168, 0.5012, 0.8439, 0.5833, 1.0874,\n","                        0.8152, 0.9191, 0.6880, 0.5020, 1.8164, 0.6923, 0.8171, 1.6122,\n","                        1.2825, 0.7260, 1.0856, 0.8562, 0.5946, 1.4423, 1.3431, 0.7443,\n","                        1.0799, 0.8057, 0.9573, 1.0118, 1.0738, 1.0422, 0.3983, 0.9857,\n","                        0.7942, 0.9313, 0.8419, 0.6930, 0.3849, 0.9540, 0.8996, 0.6741,\n","                        1.7214, 1.0010, 0.9563, 1.4588, 1.0947, 0.4992, 0.6660, 0.5810,\n","                        0.7888, 1.1260, 0.8162, 1.6338, 1.0069, 1.0089, 0.6532, 2.4365,\n","                        1.1120, 1.3254, 0.9270, 0.6976, 1.5049, 1.3558, 0.7200, 0.6390,\n","                        0.4836, 0.9714, 0.6043, 0.7502, 0.5929, 1.2089, 1.1176, 0.5037,\n","                        0.9332, 0.7642, 1.8793, 1.2482, 0.9007, 0.6322, 1.8718, 0.8407,\n","                        0.5879, 0.8506, 0.8792, 1.1257, 1.3409, 0.7195, 0.8241, 1.1275,\n","                        0.8334, 0.5267, 3.0138, 1.4069, 0.6752, 0.8888, 0.8974, 0.7288,\n","                        1.1476, 0.9443, 0.8865, 1.0069, 0.8893, 0.6850, 0.6347, 0.9852,\n","                        1.0464, 1.0238, 1.1742, 1.1559, 0.5989, 1.1481, 1.0700, 1.0395,\n","                        0.6932, 1.0777, 1.1388, 0.6932, 0.7804, 0.9315, 0.5276, 0.9296,\n","                        1.5656, 1.4179, 0.5601, 0.7208, 0.7405, 2.4365, 2.6939, 0.8775,\n","                        0.8911, 0.7361, 0.9208, 0.6336, 0.6658, 0.4344, 1.2227, 1.9823,\n","                        0.9190, 0.7259, 0.6854, 0.8690, 1.2601, 0.4971, 1.3840, 0.7782,\n","                        1.0564, 1.5312, 1.2955, 0.8760, 0.6320, 0.7251, 1.2115, 0.9386,\n","                        0.6597, 0.8626, 0.7313, 0.5891, 0.8657, 0.4266, 1.1194, 0.7169,\n","                        0.6316, 0.9080, 0.6879, 0.6047, 1.4583, 1.3874, 0.7236, 1.2905,\n","                        0.8196, 0.9458, 1.2083, 0.7606, 0.5579, 2.7823, 0.8844, 1.5391,\n","                        0.7329, 1.4984, 1.7776, 0.8225, 0.8743, 0.8482, 0.7843, 0.6751,\n","                        0.9566, 0.9311, 0.4880, 0.6768, 1.2517, 1.4030, 0.8684, 1.4144,\n","                        0.5314, 0.6038, 2.0484, 1.0713, 1.3606, 1.0304, 0.5053, 0.8157,\n","                        0.6528, 0.8498, 0.6023, 0.8875, 0.9973, 0.6355, 1.0485, 0.8294,\n","                        1.2231, 0.7279, 1.0608, 0.9665, 1.2546, 0.7297, 1.1359, 1.1186,\n","                        1.0972, 1.5473, 0.7602, 1.1264, 1.0755, 0.9602, 1.6526, 1.1577,\n","                        1.8933, 0.9148, 1.5656, 1.2416, 1.0569, 1.7551, 0.9526, 1.3036,\n","                        1.1947, 0.7721, 0.8841, 1.2468, 0.7906, 0.6733, 0.7637, 0.8858,\n","                        1.2360, 0.6864, 1.2343, 1.2617, 0.7015, 0.8080, 0.7579, 0.4697,\n","                        0.5931, 0.7968, 1.1285, 0.4869, 0.6568, 0.4460, 0.9136, 1.0332,\n","                        0.7231, 0.5881, 0.5833, 0.9627, 1.0940, 2.1832, 1.0504, 0.9235,\n","                        1.1606, 0.4957, 1.2153, 0.7738, 0.5527, 1.4999, 0.8698, 1.9353,\n","                        0.9225, 0.7616, 1.1030, 0.5861, 0.5159, 1.9262, 0.6667, 0.8456,\n","                        0.6528, 0.6113, 0.8003, 0.9010, 2.1881, 1.0803, 0.7248, 0.8509,\n","                        0.7432, 0.9582, 0.5629, 0.9001, 1.1298, 1.1949, 0.8733, 0.6130,\n","                        0.6803, 1.3739, 0.9509, 0.9144, 1.4025, 0.9504, 0.3305, 1.4394,\n","                        0.7687, 0.7225, 1.0673, 1.3295, 0.7810, 0.7558, 1.0291, 1.3729,\n","                        0.9878, 2.3381, 1.0837, 0.9912, 1.0470, 1.2513, 0.6602, 1.0198,\n","                        0.7812, 0.7622, 0.7252, 1.1220, 0.8330, 0.8897, 0.3050, 0.6104,\n","                        0.6173, 1.2442, 1.1906, 0.7310, 0.4245, 1.1388, 0.6020, 0.9119,\n","                        0.6392, 0.5044, 1.1068, 0.9258, 1.2964, 0.8755, 1.3897, 1.2430,\n","                        0.6368, 1.0195, 0.9853, 0.6010, 0.5471, 0.6906, 0.6712, 0.8548,\n","                        1.1483, 0.7621, 1.5286, 0.4849, 0.9548, 0.9419, 1.0806, 0.5386,\n","                        1.3022, 0.8189, 1.1229, 0.8273, 0.5227, 0.9137, 0.4591, 1.0099,\n","                        1.1719, 1.1618, 1.2013, 0.9800, 0.8106, 1.1093, 0.7720, 0.8957,\n","                        0.7877, 0.6404, 0.6121, 1.3812, 1.0280, 0.5641, 1.4965, 1.0223,\n","                        0.5524, 0.6442, 0.8878, 0.6841, 0.5214, 1.3412, 1.0826, 2.3860,\n","                        0.6717, 1.3073, 1.1593, 0.8726, 0.7302, 1.7213, 0.4911, 0.9137,\n","                        0.9365, 1.1013, 0.6529, 1.0176, 0.7221, 1.0508, 0.7443, 0.8538,\n","                        2.1446, 0.9552, 0.9157, 0.8489, 0.7582, 1.0810, 1.3320, 0.5707,\n","                        0.7662, 1.1953, 1.9840, 0.9654, 1.2291, 1.5025, 1.0649, 0.5375,\n","                        0.9275, 0.6754, 0.8150, 0.8210, 1.0960, 0.6927, 0.8200, 1.1455,\n","                        2.3326, 0.9754, 0.5388, 1.2842, 0.6248, 1.1921, 1.3339, 1.2269,\n","                        0.6726, 0.6665, 0.5187, 0.5805, 0.4692, 1.0306, 0.6422, 0.6480]]],\n","                     device='cuda:0')),\n","             ('model.layers.6.weight',\n","              tensor([[ 0.0573, -0.0151, -0.0212,  ...,  0.0119,  0.0139,  0.0161],\n","                      [-0.0334,  0.0407, -0.0501,  ...,  0.0275,  0.0044,  0.0148],\n","                      [ 0.0159,  0.0365, -0.0103,  ..., -0.0157,  0.0147,  0.0128],\n","                      ...,\n","                      [ 0.0046, -0.0282,  0.0413,  ..., -0.0458, -0.0595, -0.0098],\n","                      [ 0.0073,  0.0111, -0.0419,  ..., -0.0047, -0.0171, -0.0273],\n","                      [ 0.0211,  0.0536, -0.0650,  ..., -0.0264, -0.0111, -0.0030]],\n","                     device='cuda:0')),\n","             ('model.layers.7.gamma',\n","              tensor([0.9996, 1.0007, 1.0016, 0.9991, 0.9992, 1.0023, 1.0037, 1.0077, 1.0020,\n","                      0.9997, 1.0006, 1.0035, 1.0033, 1.0010, 1.0024, 1.0016, 0.9977, 0.9993,\n","                      1.0005, 1.0016, 1.0053, 1.0025, 0.9999, 1.0012, 0.9986, 1.0022, 1.0041,\n","                      1.0025, 1.0013, 1.0016, 1.0043, 1.0038, 1.0023, 0.9995, 1.0002, 1.0030,\n","                      1.0004, 1.0036, 1.0022, 1.0020, 0.9988, 1.0006, 0.9998, 1.0017, 1.0031,\n","                      1.0038, 1.0054, 1.0056, 0.9987, 1.0043, 1.0001, 1.0015, 1.0001, 1.0070,\n","                      1.0024, 0.9991, 0.9985, 1.0075, 0.9973, 1.0031, 1.0015, 0.9983, 0.9963,\n","                      1.0003, 1.0020, 1.0027, 1.0071, 1.0013, 0.9999, 1.0064, 1.0033, 1.0017,\n","                      1.0005, 0.9995, 1.0023, 1.0014, 0.9985, 1.0033, 1.0007, 0.9976, 0.9986,\n","                      1.0001, 1.0035, 1.0012, 0.9992, 1.0025, 1.0014, 1.0001, 1.0025, 1.0010,\n","                      1.0013, 1.0052, 1.0032, 1.0001, 0.9980, 1.0032, 1.0032, 0.9980, 1.0036,\n","                      1.0069, 1.0017, 1.0066, 1.0049, 1.0008, 1.0010, 0.9976, 0.9988, 0.9998,\n","                      0.9978, 0.9981, 1.0017, 1.0050, 0.9997, 1.0024, 1.0000, 0.9998, 0.9991,\n","                      1.0022, 1.0054, 0.9996, 0.9995, 1.0014, 1.0016, 1.0024, 0.9990, 1.0031,\n","                      0.9978, 1.0059, 1.0023, 0.9990, 1.0004, 0.9995, 1.0002, 1.0023, 1.0097,\n","                      1.0008, 1.0044, 1.0034, 1.0051, 1.0033, 0.9992, 0.9990, 1.0042, 0.9991,\n","                      1.0034, 1.0023, 1.0024, 1.0023, 1.0045, 1.0013, 1.0033, 1.0001, 1.0018,\n","                      0.9998, 1.0056, 1.0022, 0.9992, 1.0001, 1.0025, 1.0038, 1.0013, 1.0010,\n","                      0.9993, 1.0021, 1.0031, 0.9997, 1.0016, 0.9957, 0.9995, 0.9999, 1.0011,\n","                      1.0023, 0.9995, 0.9985, 1.0003, 0.9993, 0.9992, 1.0040, 1.0018, 1.0003,\n","                      1.0015, 0.9985, 1.0010, 1.0018, 1.0009, 1.0049, 0.9996, 1.0065, 1.0018,\n","                      0.9969, 1.0041, 1.0058, 1.0060, 1.0042, 0.9982, 1.0001, 0.9988, 1.0015,\n","                      0.9989, 1.0003, 1.0012, 1.0009, 1.0031, 1.0016, 1.0057, 1.0014, 1.0022,\n","                      1.0061, 1.0016, 1.0030, 1.0044, 1.0000, 1.0009, 1.0018, 1.0006, 0.9993,\n","                      1.0028, 1.0008, 1.0018, 1.0015, 1.0008, 1.0011, 1.0081, 1.0031, 1.0047,\n","                      1.0021, 0.9997, 1.0021, 1.0021, 1.0038, 1.0069, 1.0004, 1.0005, 0.9972,\n","                      1.0000, 1.0077, 1.0055, 1.0001, 1.0026, 1.0042, 1.0008, 0.9993, 1.0019,\n","                      1.0016, 1.0019, 1.0017, 0.9989, 1.0009, 1.0027, 1.0013, 0.9994, 1.0057,\n","                      1.0015, 1.0034, 1.0024, 1.0002, 0.9966, 0.9986, 1.0002, 1.0036, 1.0024,\n","                      1.0018, 1.0024, 1.0006, 1.0004, 1.0018, 1.0064, 1.0036, 1.0008, 1.0014,\n","                      1.0024, 1.0043, 1.0009, 1.0052, 0.9991, 1.0005, 1.0031, 1.0004, 1.0006,\n","                      0.9987, 1.0014, 0.9986, 0.9981, 0.9985, 1.0045, 0.9997, 1.0013, 0.9991,\n","                      1.0015, 0.9997, 1.0013, 1.0068, 1.0011, 0.9967, 1.0042, 1.0010, 1.0005,\n","                      0.9993, 1.0037, 0.9999, 1.0023, 1.0000, 0.9991, 1.0006, 1.0010, 1.0026,\n","                      0.9985, 1.0054, 1.0027, 1.0035, 1.0009, 1.0027, 0.9997, 0.9991, 1.0014,\n","                      1.0009, 0.9971, 1.0012, 1.0009, 0.9993, 0.9994, 1.0025, 1.0099, 1.0017,\n","                      0.9998, 1.0050, 0.9996, 1.0067, 1.0062, 1.0000, 0.9972, 1.0035, 1.0005,\n","                      0.9993, 1.0019, 1.0012, 0.9996, 0.9991, 1.0008, 1.0059, 0.9989, 1.0038,\n","                      1.0116, 1.0029, 1.0007, 0.9996, 1.0039, 1.0045, 1.0013, 1.0002, 1.0033,\n","                      1.0039, 1.0004, 1.0031, 1.0007, 0.9991, 0.9985, 1.0005, 1.0029, 1.0011,\n","                      1.0020, 1.0021, 1.0086, 1.0013, 1.0019, 1.0011, 0.9985, 1.0048, 0.9991,\n","                      1.0003, 0.9989, 0.9986, 1.0025, 1.0014, 0.9984, 0.9991, 1.0005, 1.0019,\n","                      1.0034, 1.0009, 0.9996, 1.0026, 1.0024, 1.0010, 1.0020, 1.0024, 1.0025,\n","                      1.0024, 1.0033, 0.9984, 1.0039, 1.0017, 0.9983, 0.9988, 1.0053, 1.0029,\n","                      1.0029, 1.0026, 0.9999, 1.0021, 1.0000, 1.0013, 0.9992, 0.9969, 1.0016,\n","                      0.9996, 1.0000, 1.0035, 1.0045, 1.0015, 1.0038, 0.9986, 1.0013, 0.9984,\n","                      1.0032, 1.0037, 1.0024, 0.9989, 1.0019, 1.0030, 1.0044, 1.0054, 0.9987,\n","                      1.0044, 1.0049, 0.9992, 0.9995, 1.0001, 1.0013, 0.9998, 1.0026, 1.0016,\n","                      0.9970, 0.9998, 1.0034, 1.0014, 0.9999, 1.0015, 1.0017, 1.0019, 0.9980,\n","                      1.0018, 1.0043, 1.0073, 0.9985, 1.0049, 1.0053, 1.0014, 1.0008, 1.0023,\n","                      0.9977, 1.0072, 1.0047, 1.0020, 1.0037, 1.0021, 1.0057, 0.9990, 1.0015,\n","                      1.0011, 1.0054, 0.9990, 1.0019, 1.0059, 1.0014, 1.0037, 1.0004, 1.0053,\n","                      0.9997, 0.9977, 0.9984, 0.9975, 1.0010, 1.0009, 0.9985, 1.0057, 1.0047,\n","                      0.9976, 1.0069, 1.0002, 1.0033, 1.0028, 1.0003, 1.0033, 1.0024, 0.9992,\n","                      1.0000, 1.0034, 1.0065, 1.0020, 1.0001, 1.0055, 1.0005, 1.0037, 1.0103,\n","                      1.0076, 1.0015, 0.9973, 1.0027, 1.0022, 1.0050, 1.0039, 1.0028, 1.0011,\n","                      1.0012, 1.0026, 1.0000, 1.0037, 1.0013, 0.9984, 1.0015, 1.0037],\n","                     device='cuda:0')),\n","             ('model.layers.7.beta',\n","              tensor([-1.3573e-03,  4.4790e-04, -1.8927e-03,  1.0462e-03,  5.3975e-04,\n","                      -2.2362e-03, -3.7669e-03,  1.2038e-03, -1.6057e-03,  1.0707e-03,\n","                       2.1459e-03,  9.0583e-04, -1.0720e-03,  2.7854e-03, -1.2237e-04,\n","                      -3.5110e-04, -4.2263e-05, -1.4005e-03,  2.0377e-03, -1.5952e-03,\n","                       2.8131e-03,  3.5902e-03,  1.2362e-03,  1.7650e-03, -7.8073e-04,\n","                      -2.6779e-03,  8.0909e-04, -5.6955e-04, -8.0711e-04, -8.7871e-04,\n","                      -1.0523e-03, -6.0646e-04,  2.4486e-03,  2.6664e-04, -1.5546e-03,\n","                      -5.0078e-03, -2.7859e-04, -1.2514e-03,  5.5227e-04, -1.1279e-03,\n","                       2.0538e-04, -9.0958e-05, -5.5003e-04, -1.5961e-03,  9.8683e-05,\n","                       1.3371e-03, -9.4105e-04, -4.4119e-04,  1.8184e-03, -2.1628e-03,\n","                      -2.4410e-03, -1.4119e-03,  3.1642e-03, -1.9548e-03, -2.0553e-03,\n","                      -5.1426e-04, -1.9923e-03, -1.9038e-03,  1.3000e-03, -1.6096e-03,\n","                      -2.3773e-03, -1.9783e-04,  5.5290e-04, -3.8159e-04, -1.2797e-03,\n","                      -9.0659e-04, -6.0608e-04,  3.5688e-03,  3.9088e-04, -1.7122e-03,\n","                      -4.2612e-03, -2.3057e-04, -5.9950e-04, -1.7270e-04, -1.0030e-03,\n","                       9.6647e-05, -1.1836e-04,  2.7318e-03,  5.1245e-04, -2.6373e-05,\n","                      -8.9317e-04, -8.1942e-04, -3.4107e-04,  6.1404e-04, -3.6070e-03,\n","                      -4.2077e-03, -1.5553e-03, -1.4730e-04,  5.0228e-03,  7.2939e-04,\n","                      -1.1837e-03, -5.4063e-04,  9.5629e-04, -1.5137e-03,  6.8199e-06,\n","                       3.6901e-03,  6.4389e-04,  2.5977e-03,  2.1803e-03,  2.7243e-03,\n","                      -9.9596e-04,  1.3409e-03,  4.9153e-04, -7.0119e-05, -2.7010e-03,\n","                       2.4392e-03,  7.8017e-04, -3.1455e-03, -1.9905e-03,  2.2296e-03,\n","                      -1.9139e-03, -2.6066e-03,  1.8240e-03, -2.1445e-03, -1.5115e-04,\n","                       1.1595e-03,  1.2267e-03,  1.4213e-03, -1.0025e-03, -4.4389e-04,\n","                      -9.8883e-04,  1.1939e-04,  2.0562e-03, -3.8306e-03,  7.1652e-04,\n","                       5.6389e-03,  1.5646e-03,  1.9890e-03,  7.5964e-04, -1.3001e-03,\n","                       6.3611e-04, -1.3599e-03,  8.7176e-04, -1.5730e-03, -3.1745e-03,\n","                      -3.1165e-04, -3.8348e-04, -8.6576e-04, -2.0336e-03, -3.6544e-04,\n","                       1.1714e-03, -1.7107e-04,  7.5832e-04, -1.2938e-03, -1.7784e-03,\n","                      -1.0549e-03,  9.9848e-04, -8.7531e-04,  3.5482e-04,  1.8121e-03,\n","                      -1.1962e-03,  2.1605e-03,  5.4883e-04,  6.4755e-04, -3.5295e-04,\n","                      -3.8851e-03,  1.5928e-03, -1.9506e-03,  1.7922e-03,  4.7202e-04,\n","                       2.9841e-03,  9.1072e-04,  1.5184e-05,  4.5475e-04,  1.8158e-03,\n","                      -6.0130e-04, -3.6603e-03, -2.8626e-03, -6.9277e-04,  6.7760e-04,\n","                      -1.1196e-03, -1.0770e-03,  6.2402e-04, -3.8664e-04,  3.1144e-04,\n","                       2.1924e-03,  1.8412e-03,  2.1309e-03, -2.3675e-06,  8.7583e-04,\n","                       7.0783e-04,  1.4107e-03,  3.6289e-03,  2.0180e-03, -1.5459e-04,\n","                       2.5935e-03, -2.0429e-05,  7.6046e-04, -3.5899e-04,  8.2116e-04,\n","                      -3.6012e-03, -8.1300e-04,  2.7112e-03,  6.3401e-04,  1.6725e-03,\n","                      -5.4625e-04,  1.2719e-04,  1.6978e-03, -3.3444e-03,  1.0844e-03,\n","                       8.7529e-04, -8.0842e-04,  2.9387e-04,  1.2401e-03,  3.1955e-04,\n","                       2.3120e-03,  1.0153e-03,  8.5610e-04,  2.5853e-03,  5.7367e-04,\n","                      -2.6235e-05,  3.2154e-03,  3.0869e-03, -2.1176e-03, -1.9625e-04,\n","                       9.6360e-04,  6.0871e-04,  2.3582e-03, -5.1669e-04, -2.0642e-04,\n","                      -8.3052e-04,  7.0769e-04, -2.1116e-03,  1.7960e-03, -1.0450e-03,\n","                      -1.1631e-03, -2.4722e-03,  2.9602e-03, -6.4911e-04, -1.8379e-03,\n","                      -2.5156e-03,  1.4500e-03,  3.1230e-03, -1.5530e-03, -2.2233e-03,\n","                       4.3985e-05,  1.2917e-03,  3.2679e-03,  2.3208e-03,  2.1247e-03,\n","                       5.7743e-04,  5.0532e-04, -1.5141e-03,  1.0866e-03,  8.8765e-04,\n","                       1.6684e-03, -4.6055e-04, -2.2580e-03,  1.7099e-03,  3.0070e-04,\n","                       4.4841e-04, -3.7479e-03,  5.8995e-04,  3.0581e-04,  1.8974e-03,\n","                       1.6236e-03, -1.4903e-03,  6.6970e-04, -1.2983e-03, -2.1484e-05,\n","                       1.8068e-03, -4.0045e-04,  1.2768e-03,  3.3938e-03,  1.2884e-03,\n","                      -1.0280e-03, -1.2602e-03,  1.8930e-03,  9.7219e-04,  4.9662e-04,\n","                       1.0142e-03, -5.3026e-03, -1.5105e-03, -1.5911e-03, -8.1839e-04,\n","                      -1.9394e-03,  1.5465e-03,  7.4817e-04,  1.1760e-03, -6.6097e-04,\n","                       6.6934e-04, -2.6674e-03, -1.2726e-03, -3.9727e-04,  1.5770e-03,\n","                       4.2240e-03, -1.2923e-03, -5.5238e-04, -5.3604e-04,  7.1083e-04,\n","                       2.8504e-05,  2.9112e-03, -9.3191e-04,  2.0774e-03, -2.0321e-03,\n","                       2.0377e-03, -1.9044e-05, -4.6209e-04,  1.5640e-03, -2.6317e-03,\n","                      -3.3633e-04,  3.9439e-03,  1.7392e-03,  5.5399e-04,  8.9065e-04,\n","                      -4.5178e-03, -1.1809e-03, -1.8187e-03, -1.8197e-03,  3.1437e-03,\n","                      -5.5767e-04,  3.1748e-04, -1.4319e-03, -1.2328e-03,  1.8818e-03,\n","                      -1.3120e-03, -4.6162e-03,  7.7106e-04, -6.6034e-04,  1.7848e-03,\n","                      -3.8801e-03, -1.7498e-03,  3.6537e-04, -1.8716e-03,  1.5077e-03,\n","                      -3.4629e-03,  1.2069e-03, -2.3910e-03, -1.4126e-03,  3.0182e-03,\n","                       2.5178e-03, -6.8097e-04, -2.1548e-04,  7.6478e-04,  4.3707e-03,\n","                       2.7575e-03, -1.3460e-03, -4.9991e-04, -2.7085e-03,  1.6787e-05,\n","                      -4.9558e-04, -3.3551e-03,  3.7059e-03, -3.2017e-04, -2.2476e-04,\n","                      -2.8535e-03, -1.2845e-03,  1.4361e-03,  2.6440e-03,  9.9983e-04,\n","                      -8.1751e-04, -5.0920e-03,  6.1740e-04, -1.7900e-03,  1.5489e-03,\n","                       9.4685e-06, -2.9055e-03,  2.0699e-03,  6.5944e-04, -1.6487e-03,\n","                      -6.8307e-05, -7.9255e-04,  5.3390e-05, -2.1882e-03,  5.1346e-03,\n","                       1.9798e-03, -1.9789e-03, -9.5511e-04, -1.9066e-03,  1.3627e-04,\n","                      -1.1630e-03,  8.5374e-04,  1.5252e-03, -1.9058e-03, -2.0569e-03,\n","                      -6.3618e-04,  1.5628e-03, -1.0890e-03, -1.2419e-03, -4.5046e-03,\n","                      -1.2865e-03, -5.7012e-03,  1.7666e-03,  6.3921e-04, -3.2679e-04,\n","                       2.2096e-03,  1.1639e-03,  3.7400e-03, -2.2343e-03,  1.0132e-03,\n","                      -1.0692e-03,  1.9445e-03,  1.0937e-03, -2.2900e-03,  4.2647e-04,\n","                       1.7456e-03, -6.9053e-04, -8.0918e-04, -1.9054e-03, -1.1773e-03,\n","                      -1.8316e-03,  5.5607e-04, -1.8209e-03, -5.2180e-04,  2.2379e-03,\n","                       9.9682e-04,  1.3627e-03, -2.5773e-03, -4.0569e-03, -6.0221e-04,\n","                      -2.9241e-05,  3.0260e-04,  1.9693e-03,  1.1940e-05,  4.3877e-04,\n","                      -2.8984e-03,  2.4264e-03,  2.2238e-03,  1.5588e-03, -1.5185e-03,\n","                      -4.4377e-04,  2.0779e-03,  2.5894e-03,  1.3724e-03, -1.0860e-03,\n","                       4.8243e-04,  1.6285e-03, -1.2498e-03,  2.1468e-03,  3.6815e-03,\n","                      -5.5916e-04,  2.8413e-03, -1.4099e-03,  3.3759e-03, -2.3149e-04,\n","                       6.6272e-04, -6.3532e-04, -3.4979e-04, -1.4834e-03,  9.1638e-04,\n","                       1.8310e-03, -1.5418e-03,  3.7957e-03,  4.6458e-03,  7.9973e-04,\n","                      -4.3192e-03, -8.8935e-04, -4.8479e-05, -7.5357e-04,  3.9266e-04,\n","                      -2.2066e-03,  2.2239e-04,  4.2535e-03, -1.1298e-03,  2.4862e-03,\n","                       2.6278e-03, -1.3938e-03, -1.0687e-03, -2.3720e-03,  1.6500e-03,\n","                       1.2981e-03, -4.5796e-03,  1.0138e-03, -1.8007e-03,  9.4372e-04,\n","                      -7.9788e-04,  7.1986e-05, -1.8381e-03, -5.4336e-04,  2.3398e-03,\n","                      -3.2965e-03, -1.3306e-03, -2.6106e-03, -1.1867e-03,  6.8612e-05,\n","                       1.5562e-04,  2.7267e-03,  3.3226e-03,  4.9909e-04,  1.5675e-03,\n","                       1.2842e-03,  2.5156e-03,  1.8533e-03,  5.1189e-04, -2.3427e-03,\n","                      -1.1104e-03, -1.9760e-03, -1.7896e-03,  2.9720e-03, -1.7840e-03,\n","                      -1.8273e-04,  2.5679e-03,  4.0584e-03,  1.7763e-03,  7.6864e-04,\n","                      -2.3973e-03, -4.0890e-04, -5.6378e-04, -2.0793e-04, -6.2485e-04,\n","                      -4.6817e-04,  9.2834e-04, -8.3002e-04, -1.3108e-03, -3.0755e-03,\n","                       2.9825e-04, -1.3196e-03, -3.7764e-03,  1.5145e-03,  1.3208e-03,\n","                       1.8701e-03, -2.7798e-03], device='cuda:0')),\n","             ('model.layers.7.running_mean',\n","              tensor([[[-5.6439e-03,  3.2551e-02,  7.0508e-02,  4.1236e-03,  7.0051e-02,\n","                         8.8432e-03,  3.7341e-03,  5.3226e-02, -9.7034e-02, -5.6791e-02,\n","                        -9.1209e-02, -1.6885e-02,  3.0827e-02,  6.1939e-02, -6.2187e-02,\n","                        -6.9917e-02, -2.6542e-02,  5.7637e-03, -5.9974e-02,  2.2427e-02,\n","                         3.8371e-02, -5.7881e-02, -3.8625e-02,  8.5619e-02,  5.2203e-02,\n","                        -5.2000e-02,  7.6147e-02, -2.5486e-02,  4.8541e-02, -1.4462e-02,\n","                         4.0084e-02, -1.1178e-02,  1.8372e-02,  1.5649e-02, -7.6984e-02,\n","                        -3.0480e-02,  4.8193e-02, -4.3712e-02,  5.9504e-02,  1.0680e-02,\n","                        -5.1741e-03, -5.1828e-02,  9.6389e-02,  1.7757e-02,  7.3423e-02,\n","                         7.8309e-02, -4.0210e-02,  1.7343e-02, -3.3488e-02, -7.1044e-02,\n","                         5.1017e-02,  1.0630e-01,  1.2067e-02,  7.9419e-03,  3.6068e-02,\n","                         5.1881e-02, -5.4236e-02,  5.4022e-02, -3.0849e-02, -9.8597e-02,\n","                        -2.9487e-02, -2.9155e-03, -8.0928e-02,  1.4319e-01, -6.4455e-02,\n","                         4.8520e-02, -6.3051e-02,  3.5069e-02, -1.4072e-01, -2.0509e-02,\n","                         8.9723e-02, -2.9208e-02,  1.7828e-02,  5.5720e-02, -6.6398e-02,\n","                        -1.9216e-03,  3.6181e-02, -1.2750e-03, -2.8167e-02, -1.3213e-02,\n","                         8.7286e-02,  1.5680e-02,  5.9062e-02,  1.2126e-02,  3.2665e-02,\n","                         1.4061e-03,  5.4117e-02, -3.7508e-03, -1.4350e-03,  4.1311e-02,\n","                        -4.7791e-03,  4.3266e-02,  3.5455e-02,  9.4321e-03,  5.1568e-02,\n","                         3.4111e-02,  1.0146e-04, -3.2979e-02, -3.4709e-02,  5.4430e-02,\n","                        -1.0130e-02, -7.9846e-02,  5.3301e-02, -4.1436e-02, -3.6426e-02,\n","                        -2.8386e-02,  5.3376e-02, -4.1454e-02,  5.5798e-02,  1.2996e-02,\n","                         1.3111e-02,  5.6370e-02, -4.0183e-02,  4.9743e-02,  2.5047e-02,\n","                        -3.4712e-02, -1.6940e-02, -9.3248e-02,  1.8801e-02,  2.1981e-02,\n","                        -2.8405e-02, -3.3721e-02, -1.4047e-02, -3.7888e-03, -3.2129e-02,\n","                         9.6600e-02,  3.9393e-02, -3.2201e-02, -3.3713e-02,  5.0677e-02,\n","                        -3.4686e-02,  6.9129e-02,  5.5603e-03,  2.0915e-03,  2.7615e-02,\n","                         4.0672e-02,  1.0801e-02, -7.6214e-03, -3.3254e-02,  8.5559e-02,\n","                        -3.4171e-02,  1.0136e-02,  6.0514e-02,  4.9208e-02,  8.6357e-02,\n","                         2.9727e-02, -4.7644e-02,  6.8674e-02, -1.4523e-02, -4.4513e-02,\n","                         7.9115e-03, -1.4340e-02, -8.3399e-02,  9.7715e-02, -4.2790e-02,\n","                        -7.3640e-02,  2.9693e-02, -1.3584e-02, -1.5386e-02, -3.9590e-02,\n","                        -3.3691e-02, -3.1171e-02, -3.9649e-02, -2.1053e-02, -4.6158e-02,\n","                         3.0399e-03,  7.6428e-02,  9.0155e-02,  6.2182e-02, -2.1618e-02,\n","                        -6.1696e-02,  6.6007e-02,  8.1783e-02, -1.7376e-02, -2.8664e-02,\n","                        -2.2767e-02,  6.9473e-03, -2.8692e-02, -6.0462e-02, -4.3104e-02,\n","                         1.2550e-02, -3.4821e-02,  9.9444e-02,  1.4766e-02,  4.4833e-02,\n","                        -4.3522e-02, -6.0390e-02,  2.1065e-02,  6.9100e-04,  1.1944e-02,\n","                         3.8378e-02, -9.3761e-03,  2.8823e-02,  1.9195e-03, -1.2890e-01,\n","                        -6.2070e-02,  1.0125e-01, -2.1047e-02, -8.8037e-02,  3.5270e-02,\n","                        -2.1601e-02,  1.3233e-01,  4.9219e-02,  4.2556e-02, -2.7320e-02,\n","                         7.0789e-03,  6.9150e-02,  1.1073e-03,  1.2444e-01,  7.1604e-02,\n","                         4.6482e-02,  2.5641e-02, -6.7402e-02,  4.6910e-03,  3.4338e-02,\n","                         3.4482e-02, -8.4193e-03, -7.6144e-02,  6.8310e-02, -1.4108e-02,\n","                         7.3907e-02,  7.7811e-02,  1.0369e-02,  1.7175e-02,  1.9943e-02,\n","                         4.0123e-02, -3.0965e-02,  8.0840e-02,  4.7340e-02, -2.5157e-02,\n","                         4.4034e-02,  2.5912e-02, -3.3629e-02,  2.2118e-02, -1.1879e-01,\n","                        -1.1501e-02,  6.9400e-02,  4.7262e-02,  8.6118e-03, -1.4221e-01,\n","                        -1.2905e-02, -2.9344e-02, -2.7751e-02,  1.7886e-02,  3.6828e-02,\n","                        -5.5715e-02, -1.7381e-02,  4.8003e-02, -3.3304e-02,  9.3029e-04,\n","                         5.2057e-02, -3.6367e-03,  2.9548e-02, -4.1750e-02, -1.0589e-01,\n","                         3.9304e-02,  6.5168e-02,  1.0321e-02,  3.3000e-02, -8.8707e-03,\n","                         5.0944e-02, -5.3729e-03, -3.6784e-03, -2.2451e-03,  2.1840e-02,\n","                        -3.5046e-02, -4.4580e-02, -1.6924e-02,  3.4079e-02, -3.2705e-04,\n","                        -3.3667e-02,  4.4755e-03,  1.7942e-02, -1.6026e-02, -1.1458e-01,\n","                         4.4159e-02, -3.0524e-02, -2.7259e-02,  8.1489e-02,  1.5567e-02,\n","                        -1.0644e-01,  1.0886e-01,  6.1609e-02,  6.9804e-02, -5.3180e-02,\n","                         8.8108e-02, -4.9893e-02, -4.9997e-03,  1.9868e-02,  2.1346e-02,\n","                         3.8929e-02,  3.7076e-02, -5.1802e-02, -2.1976e-02, -5.6789e-02,\n","                        -3.0864e-02,  1.5177e-02, -3.1721e-02, -1.5977e-03,  3.5988e-03,\n","                        -5.2385e-02, -1.2765e-01, -2.2564e-02,  9.1664e-03, -7.9726e-02,\n","                        -7.4105e-03,  2.5994e-02, -6.0530e-03, -4.7722e-02, -3.1386e-02,\n","                        -2.2606e-02,  5.1567e-03, -1.6386e-02, -6.8974e-02, -7.2715e-02,\n","                        -3.3691e-02, -4.2192e-02, -8.3663e-02,  1.6810e-02, -6.5983e-02,\n","                         3.7384e-02, -7.0222e-02,  3.0875e-02,  2.5672e-02, -4.4083e-02,\n","                         4.5709e-02,  8.8237e-02,  3.9616e-02, -2.1129e-02, -4.4492e-04,\n","                        -1.7702e-02, -6.5447e-02,  1.6244e-02,  7.7130e-02, -7.4149e-02,\n","                         1.3169e-02,  8.3401e-02, -5.5752e-03,  1.3257e-02,  1.3670e-02,\n","                        -1.0179e-01,  3.8388e-02, -1.1229e-02, -1.2220e-02,  2.2779e-02,\n","                         1.3599e-01, -1.2511e-03, -2.3483e-02,  1.9872e-02,  3.5800e-02,\n","                         5.8629e-03, -7.7037e-03, -3.9731e-02, -2.8513e-02, -1.2590e-02,\n","                         3.7152e-02,  5.4881e-02, -7.9113e-03, -2.1485e-03,  2.4262e-03,\n","                         8.1643e-02, -1.2257e-02, -6.2762e-04, -2.7308e-02, -1.0610e-02,\n","                        -1.7882e-02, -4.2846e-02, -1.0417e-01, -2.4253e-02,  6.9420e-02,\n","                        -3.6549e-03, -7.8173e-03, -2.1514e-02,  2.8120e-02,  9.7694e-02,\n","                         8.3192e-02, -5.5097e-03, -3.7234e-02,  1.9187e-02, -6.4904e-03,\n","                        -2.3065e-02,  3.5387e-02, -5.7811e-02, -5.1753e-02,  1.2396e-02,\n","                        -1.7745e-02,  3.1548e-02, -6.7323e-02, -4.2143e-02,  3.3598e-02,\n","                         3.7304e-02, -1.9017e-02,  1.1084e-02,  2.1162e-02, -4.1181e-02,\n","                         5.2880e-02,  3.6352e-02,  2.1806e-02, -6.7392e-03,  8.6565e-03,\n","                         3.8792e-02,  1.8576e-02, -1.4442e-02, -5.7598e-02,  6.8840e-03,\n","                         2.5656e-02, -3.3060e-02, -4.2503e-02,  7.2925e-04,  2.1963e-02,\n","                        -4.9994e-02, -7.6083e-02,  9.1261e-02, -3.1588e-02,  2.1107e-02,\n","                        -3.1748e-03,  2.3046e-02,  5.8577e-02,  1.9993e-02,  3.6207e-02,\n","                        -1.1067e-02, -1.6653e-02, -8.0935e-02,  4.5644e-02, -2.5412e-02,\n","                         2.1036e-02,  3.4105e-03,  1.7195e-02,  3.3555e-02, -7.0580e-02,\n","                         4.9060e-02, -6.5471e-02,  3.7334e-03,  5.7214e-02, -2.5538e-02,\n","                        -7.6037e-03,  4.8953e-02, -1.0654e-01,  7.9106e-03,  6.4260e-03,\n","                        -9.2375e-02, -2.9456e-02,  4.3919e-02, -4.8689e-02, -9.7987e-03,\n","                        -2.2224e-02, -8.1727e-03, -1.1032e-02,  2.1454e-02, -4.6775e-02,\n","                         7.9573e-02,  1.0464e-01, -2.0447e-02, -2.2264e-03, -1.4198e-02,\n","                         6.7850e-02, -1.7717e-02, -7.4177e-02, -1.4890e-03, -6.0456e-02,\n","                         4.9364e-02,  1.6757e-02,  5.2570e-02,  5.0215e-02,  2.3413e-03,\n","                        -5.5560e-02, -1.8725e-02,  2.0007e-02, -4.3792e-02, -5.0467e-02,\n","                         4.0830e-02, -9.7732e-03, -6.3635e-03, -9.6099e-02, -7.2357e-02,\n","                         1.6975e-02,  5.1510e-02,  1.8555e-02,  2.2434e-02,  7.7344e-02,\n","                        -1.5985e-02, -1.1707e-01, -2.6543e-02,  3.5878e-02, -4.1306e-03,\n","                        -1.2621e-02,  7.9543e-03, -2.1926e-02, -2.9547e-02,  2.2294e-02,\n","                         4.1214e-02, -3.2085e-02, -1.3177e-02,  3.7293e-02,  2.1534e-02,\n","                         9.7844e-02, -5.2096e-02,  3.6338e-02,  6.1833e-02,  2.5948e-02,\n","                         5.5956e-02, -7.8446e-02, -3.2895e-02, -9.2554e-02,  1.2731e-01,\n","                         4.4233e-02, -1.3768e-02,  3.7642e-03,  4.2347e-02, -4.3514e-03,\n","                         1.6467e-02,  4.0945e-02]]], device='cuda:0')),\n","             ('model.layers.7.running_var',\n","              tensor([[[0.6369, 0.3840, 0.2980, 0.9339, 0.4820, 0.1507, 0.3045, 0.1709,\n","                        0.6318, 0.2856, 0.3367, 0.2936, 0.3036, 0.3513, 0.3871, 0.2628,\n","                        0.4459, 0.2735, 0.2246, 0.4144, 0.2252, 0.3210, 0.3615, 0.3101,\n","                        0.5836, 0.3059, 0.1804, 0.3790, 0.4596, 0.3562, 0.3468, 0.3399,\n","                        0.1930, 0.6639, 0.4300, 0.3907, 0.2826, 0.2906, 0.3306, 0.3321,\n","                        0.7978, 0.2702, 0.5136, 0.5602, 0.2164, 0.2751, 0.1773, 0.2727,\n","                        0.4234, 0.2277, 0.7927, 0.3017, 0.4258, 0.1728, 0.3479, 0.2490,\n","                        0.4365, 0.1605, 0.4456, 0.3408, 0.4419, 0.3547, 0.7357, 0.4587,\n","                        0.4205, 0.2522, 0.3197, 0.5929, 0.4307, 0.1645, 0.2217, 0.2989,\n","                        0.3364, 0.4637, 0.2635, 0.4576, 0.5050, 0.2204, 0.4743, 0.3164,\n","                        0.4752, 0.2055, 0.2776, 0.2398, 0.1901, 0.2137, 0.3921, 0.4164,\n","                        0.2924, 0.4070, 0.3343, 0.2583, 0.4200, 0.3192, 0.4413, 0.2325,\n","                        0.5939, 0.4142, 0.3527, 0.2198, 0.3432, 0.3768, 0.2270, 0.3157,\n","                        0.2774, 0.6371, 0.4007, 0.4371, 0.4007, 0.4558, 0.2553, 0.1839,\n","                        0.4202, 0.2431, 0.5894, 0.8221, 0.3157, 0.4392, 0.2056, 0.6407,\n","                        1.3130, 0.2444, 0.5891, 0.2874, 0.5276, 0.2400, 0.6410, 0.2201,\n","                        0.2642, 0.5028, 0.3520, 0.4011, 0.2974, 0.3516, 0.2450, 0.3604,\n","                        0.3158, 0.2425, 0.2054, 0.3304, 0.6066, 0.4481, 0.2783, 0.5995,\n","                        0.3090, 0.1567, 0.2863, 0.2461, 0.4161, 0.5354, 0.3499, 0.2338,\n","                        0.2462, 0.3705, 0.1559, 0.2848, 0.3533, 0.3194, 0.4310, 0.3000,\n","                        0.3119, 0.3104, 0.4477, 0.2847, 0.1602, 0.3224, 0.4500, 0.4247,\n","                        0.7596, 0.5153, 0.2527, 0.2727, 0.9224, 0.4109, 0.5311, 0.2893,\n","                        0.3702, 0.2606, 0.3422, 0.2243, 0.3669, 0.5225, 0.2645, 0.2924,\n","                        0.3433, 0.1875, 0.3488, 0.1771, 0.4177, 0.5069, 0.2387, 0.2067,\n","                        0.1658, 0.1120, 0.5067, 0.4231, 0.4250, 0.2658, 0.6962, 0.3516,\n","                        0.2569, 0.3401, 0.2283, 0.2900, 0.2464, 0.2349, 0.3048, 0.1873,\n","                        0.2942, 0.3275, 0.2365, 0.4264, 0.3951, 0.4928, 0.6713, 0.3757,\n","                        0.2694, 0.2490, 0.3279, 0.4194, 0.7565, 0.4467, 0.2305, 0.3375,\n","                        0.2718, 0.4299, 0.3156, 0.2263, 0.2560, 0.2813, 0.2398, 0.4178,\n","                        0.3424, 0.4004, 0.4107, 0.1661, 0.2092, 0.3341, 0.4052, 0.3498,\n","                        0.3837, 0.2924, 0.6998, 0.5567, 0.3752, 0.3151, 0.4273, 0.4470,\n","                        0.2842, 0.2820, 0.2616, 0.3385, 0.2522, 0.2393, 0.3977, 0.2812,\n","                        1.5689, 0.7512, 0.4327, 0.3213, 0.4373, 0.5957, 0.2673, 0.3856,\n","                        0.5007, 0.2628, 0.1579, 0.3093, 0.1807, 0.2255, 0.3695, 0.2425,\n","                        0.4308, 0.1510, 0.4224, 0.3964, 0.2533, 0.4590, 0.3117, 0.2929,\n","                        0.2621, 0.6317, 0.3677, 0.4701, 0.2974, 0.3255, 0.2922, 0.3423,\n","                        0.2970, 0.3746, 0.2889, 0.1668, 0.4262, 0.6692, 0.2434, 0.1984,\n","                        0.8051, 0.7209, 0.2151, 0.3345, 0.2829, 0.5566, 0.2958, 0.2670,\n","                        0.3920, 0.3307, 0.6153, 0.2403, 0.3329, 0.2773, 0.4531, 0.2620,\n","                        0.2808, 0.4957, 0.4561, 0.3646, 0.4984, 0.3901, 0.3386, 0.3833,\n","                        0.3958, 0.2913, 0.2973, 0.2990, 0.4373, 0.3065, 0.2871, 0.1528,\n","                        0.2664, 0.3275, 0.4628, 0.4556, 0.6763, 0.4746, 0.3105, 0.2709,\n","                        0.7226, 0.8373, 0.4547, 0.2443, 0.5489, 0.2183, 0.1953, 0.2590,\n","                        0.4488, 0.4417, 0.2589, 0.2404, 0.4004, 0.3948, 0.1912, 0.2795,\n","                        0.2757, 0.2476, 0.2001, 0.4481, 0.3784, 0.4792, 0.3088, 0.3222,\n","                        0.3171, 0.5661, 0.1585, 0.4208, 0.2302, 0.4977, 0.4406, 0.1822,\n","                        1.2386, 0.4446, 0.4947, 0.4999, 0.3225, 0.2690, 0.3791, 0.3024,\n","                        0.5522, 0.1402, 0.2894, 0.2648, 0.4786, 0.2711, 0.2336, 0.5247,\n","                        0.3277, 0.2734, 0.3872, 0.2381, 0.2553, 0.4863, 0.2221, 0.3207,\n","                        0.7032, 0.7446, 0.2065, 0.2542, 0.3356, 0.3139, 0.3949, 0.2683,\n","                        0.3329, 0.3431, 0.2667, 0.5265, 0.3464, 0.3859, 0.2886, 0.3592,\n","                        0.3902, 0.3671, 0.2204, 0.3432, 0.3742, 0.4307, 0.2755, 0.2547,\n","                        0.3345, 0.3436, 0.3733, 0.2394, 0.2189, 0.1367, 0.7716, 0.2140,\n","                        0.2056, 0.4622, 0.3856, 0.5049, 0.3596, 0.5110, 0.2633, 0.3795,\n","                        0.7192, 0.4071, 0.2151, 0.3351, 0.5881, 0.5279, 0.3217, 0.2003,\n","                        0.4555, 0.2634, 0.2429, 0.2035, 0.4142, 0.2936, 0.2794, 0.1953,\n","                        0.4538, 0.4179, 0.5718, 0.1568, 0.3663, 0.4457, 0.2099, 0.4087,\n","                        0.4430, 0.3651, 0.2564, 0.3316, 0.1205, 0.2887, 0.2358, 0.2126,\n","                        0.2318, 0.2089, 0.3730, 0.2343, 0.6166, 0.3683, 0.5458, 0.5520,\n","                        0.4272, 0.3120, 0.5313, 0.2500, 0.2879, 0.3895, 0.2278, 0.3452,\n","                        0.2521, 0.3106, 0.3944, 0.2973, 0.2775, 0.8506, 0.2966, 0.4204,\n","                        0.2496, 0.3816, 0.2710, 0.2175, 0.3599, 0.4177, 0.1311, 0.2317,\n","                        0.4278, 0.9603, 0.2527, 0.1994, 0.2594, 0.2009, 0.3917, 0.2828,\n","                        0.2964, 0.3472, 0.6023, 0.3253, 0.3771, 0.4020, 0.2922, 0.2370]]],\n","                     device='cuda:0')),\n","             ('model.layers.10.weight',\n","              tensor([[ 1.2355e-02,  3.1704e-03, -4.0412e-02,  ...,  1.6147e-02,\n","                        2.7579e-02, -2.6205e-02],\n","                      [ 3.7988e-02,  4.6269e-03, -3.9334e-02,  ..., -9.5206e-03,\n","                       -1.4010e-03,  3.2481e-02],\n","                      [ 1.4935e-03,  1.6953e-02,  5.8657e-03,  ..., -4.7024e-05,\n","                       -3.4958e-02, -2.3952e-02],\n","                      ...,\n","                      [ 2.0689e-02,  3.6086e-02, -3.8182e-02,  ..., -7.6246e-02,\n","                       -4.0513e-03,  1.1358e-02],\n","                      [-4.6037e-02, -2.9345e-02, -2.1653e-03,  ...,  2.7492e-02,\n","                        2.2744e-02, -1.9540e-02],\n","                      [-8.2250e-03,  2.2184e-02, -6.4664e-03,  ...,  2.6560e-02,\n","                       -2.0072e-02, -3.9602e-03]], device='cuda:0')),\n","             ('model.layers.11.gamma',\n","              tensor([1.0047, 1.0180, 1.0074, 1.0115, 1.0053, 1.0092, 1.0060, 1.0146, 1.0124,\n","                      1.0090, 1.0106, 1.0043, 1.0118, 1.0053, 1.0083, 1.0144, 1.0081, 1.0088,\n","                      1.0147, 1.0087, 1.0063, 1.0114, 1.0072, 1.0141, 1.0083, 1.0047, 1.0071,\n","                      1.0089, 1.0087, 1.0083, 1.0133, 1.0046, 1.0100, 1.0137, 1.0148, 1.0081,\n","                      1.0081, 1.0079, 1.0130, 1.0073, 1.0094, 1.0067, 1.0153, 1.0081, 1.0076,\n","                      1.0087, 1.0065, 1.0098, 1.0036, 1.0085, 1.0135, 1.0159, 1.0157, 1.0075,\n","                      1.0116, 1.0039, 1.0053, 1.0202, 1.0189, 1.0084, 1.0134, 1.0092, 1.0184,\n","                      1.0124, 1.0150, 1.0074, 1.0101, 1.0123, 1.0171, 1.0204, 1.0107, 1.0081,\n","                      1.0126, 1.0263, 1.0141, 1.0133, 1.0019, 1.0063, 1.0115, 1.0072, 1.0060,\n","                      1.0075, 1.0050, 1.0139, 1.0052, 1.0044, 1.0098, 1.0077, 1.0089, 1.0111,\n","                      1.0083, 1.0100, 1.0066, 1.0127, 1.0227, 1.0095, 1.0076, 1.0134, 1.0039,\n","                      1.0120, 1.0117, 1.0055, 1.0263, 1.0026, 1.0097, 1.0082, 1.0094, 1.0116,\n","                      1.0076, 1.0117, 1.0246, 1.0141, 1.0066, 1.0061, 1.0044, 1.0096, 1.0064,\n","                      1.0088, 1.0073, 1.0204, 1.0111, 1.0134, 1.0100, 1.0108, 1.0138, 1.0080,\n","                      1.0088, 1.0147, 1.0139, 1.0022, 1.0114, 1.0079, 1.0104, 1.0079, 1.0111,\n","                      1.0091, 1.0123, 1.0059, 1.0070, 1.0134, 1.0044, 1.0137, 1.0103, 1.0098,\n","                      1.0057, 1.0121, 1.0120, 1.0121, 1.0040, 1.0113, 1.0125, 1.0058, 1.0091,\n","                      1.0129, 1.0075, 1.0153, 1.0083, 1.0036, 1.0103, 1.0124, 1.0090, 1.0070,\n","                      1.0168, 1.0132, 1.0164, 1.0072, 1.0121, 1.0098, 1.0065, 1.0113, 1.0077,\n","                      1.0128, 1.0082, 1.0124, 1.0195, 1.0071, 1.0115, 1.0122, 1.0106, 1.0043,\n","                      1.0068, 1.0107, 1.0127, 1.0076, 1.0119, 1.0142, 1.0082, 1.0102, 1.0042,\n","                      1.0143, 1.0093, 1.0073, 1.0022, 1.0060, 1.0112, 1.0073, 1.0140, 1.0083,\n","                      1.0049, 1.0170, 1.0058, 1.0124, 1.0089, 1.0066, 1.0144, 1.0105, 1.0106,\n","                      1.0033, 1.0068, 1.0088, 1.0065, 1.0087, 1.0105, 1.0152, 1.0162, 1.0135,\n","                      1.0103, 1.0111, 1.0045, 1.0178, 1.0196, 1.0115, 1.0096, 1.0177, 1.0042,\n","                      1.0127, 1.0092, 1.0059, 1.0048, 1.0064, 1.0128, 1.0064, 1.0089, 1.0111,\n","                      1.0142, 1.0097, 1.0149, 1.0121, 1.0142, 1.0117, 1.0121, 1.0142, 1.0085,\n","                      1.0092, 1.0168, 1.0055, 1.0153, 1.0108, 1.0129, 1.0092, 1.0083, 1.0178,\n","                      1.0049, 1.0139, 1.0116, 1.0046, 1.0171, 1.0150, 1.0156, 1.0109, 1.0152,\n","                      1.0153, 1.0129, 1.0107, 1.0114, 1.0040, 1.0117, 1.0074, 1.0095, 1.0083,\n","                      1.0082, 1.0153, 1.0078, 1.0122, 1.0114, 1.0096, 1.0082, 1.0074, 1.0106,\n","                      1.0045, 1.0104, 1.0102, 1.0218, 1.0051, 1.0121, 1.0067, 1.0105, 1.0066,\n","                      1.0073, 1.0054, 1.0087, 1.0133, 1.0096, 1.0070, 1.0095, 1.0098, 1.0089,\n","                      1.0093, 1.0163, 1.0096, 1.0048, 1.0076, 1.0148, 1.0117, 1.0124, 1.0062,\n","                      1.0067, 1.0157, 1.0120, 1.0078, 1.0099, 1.0117, 1.0169, 1.0099, 1.0149,\n","                      1.0097, 1.0132, 1.0182, 1.0045, 1.0060, 1.0080, 1.0107, 1.0084, 1.0042,\n","                      1.0066, 1.0136, 1.0064, 1.0101, 1.0080, 1.0141, 1.0077, 1.0087, 1.0088,\n","                      1.0110, 1.0147, 1.0062, 1.0087, 1.0246, 1.0045, 1.0150, 1.0079, 1.0151,\n","                      1.0094, 1.0048, 1.0092, 1.0076, 1.0187, 1.0091, 1.0171, 1.0051, 1.0081,\n","                      1.0078, 1.0040, 1.0091, 1.0153, 1.0221, 1.0045, 1.0116, 1.0109, 1.0083,\n","                      1.0057, 1.0157, 1.0139, 1.0092, 1.0046, 1.0071, 1.0139, 1.0180, 1.0145,\n","                      1.0056, 1.0030, 1.0109, 1.0057, 1.0074, 1.0093, 1.0168, 1.0108, 1.0156,\n","                      1.0059, 1.0169, 1.0103, 1.0026, 1.0104, 1.0083, 1.0148, 1.0144, 1.0134,\n","                      1.0135, 1.0129, 1.0130, 1.0045, 1.0106, 1.0110, 1.0076, 1.0173, 1.0091,\n","                      1.0070, 1.0102, 1.0037, 1.0165, 1.0022, 1.0127, 1.0115, 1.0092, 1.0140,\n","                      1.0100, 1.0130, 1.0066, 1.0087, 1.0114, 1.0154, 1.0106, 1.0089, 1.0164,\n","                      1.0152, 1.0065, 1.0142, 1.0022, 1.0073, 1.0116, 1.0063, 1.0041, 1.0056,\n","                      1.0073, 1.0138, 1.0043, 1.0140, 1.0094, 1.0105, 1.0120, 1.0125, 1.0093,\n","                      1.0086, 1.0142, 1.0035, 1.0173, 1.0181, 1.0113, 1.0077, 1.0114, 1.0062,\n","                      1.0084, 1.0187, 1.0034, 1.0150, 1.0126, 1.0121, 1.0133, 1.0060, 1.0135,\n","                      1.0091, 1.0167, 1.0158, 1.0044, 1.0086, 1.0028, 1.0109, 1.0178, 1.0056,\n","                      1.0139, 1.0040, 1.0154, 1.0085, 1.0183, 1.0112, 1.0103, 1.0087, 1.0089,\n","                      1.0103, 1.0195, 1.0051, 1.0058, 1.0196, 1.0128, 1.0102, 1.0066, 1.0129,\n","                      1.0129, 1.0174, 1.0116, 1.0151, 1.0161, 1.0093, 1.0151, 1.0103, 1.0086,\n","                      1.0056, 1.0120, 1.0041, 1.0127, 1.0101, 1.0068, 1.0077, 1.0064, 1.0092,\n","                      1.0082, 1.0147, 1.0081, 1.0172, 1.0057, 1.0081, 1.0146, 1.0172, 1.0085,\n","                      1.0100, 1.0092, 1.0065, 1.0082, 1.0047, 1.0052, 1.0110, 1.0073],\n","                     device='cuda:0')),\n","             ('model.layers.11.beta',\n","              tensor([-1.2755e-03, -1.7750e-03,  1.1886e-03,  7.3671e-03,  2.6393e-04,\n","                      -9.8481e-04, -7.4010e-03,  6.2721e-03,  3.6511e-03, -5.0842e-03,\n","                      -3.6472e-05, -4.2128e-03,  2.6850e-03, -3.4419e-03, -3.8313e-04,\n","                       2.4141e-03,  3.1039e-03,  4.5759e-04, -4.9823e-03, -9.7454e-04,\n","                       4.3326e-03, -1.1192e-03,  3.9986e-03, -2.5266e-03, -5.8262e-04,\n","                      -1.5682e-03,  1.0474e-05,  2.6552e-03,  2.9479e-03,  7.5673e-04,\n","                       1.9920e-03, -4.5765e-03, -2.3622e-03,  1.2825e-03, -1.4080e-03,\n","                      -9.0623e-04, -1.5780e-03, -3.3473e-03, -4.4138e-04, -4.4563e-03,\n","                      -1.1258e-03, -1.5803e-03,  1.4478e-03,  7.2799e-04,  3.5985e-03,\n","                       6.5213e-03,  5.8521e-03,  1.3674e-03, -5.7766e-03,  7.0409e-04,\n","                       4.0023e-03, -3.4641e-04, -1.8151e-03,  2.4252e-03, -1.5888e-03,\n","                      -2.4452e-03, -5.6923e-05,  3.5507e-03,  4.7988e-03, -4.0426e-03,\n","                       2.8366e-03,  5.1038e-03,  1.2102e-03,  2.7422e-03,  9.3029e-04,\n","                      -2.6155e-03, -5.9098e-04,  3.6863e-03, -1.1873e-03, -1.6115e-03,\n","                      -2.3655e-03, -3.1475e-03,  1.3785e-03, -6.0229e-03,  3.7837e-03,\n","                      -2.4274e-03,  1.6203e-03, -1.4615e-03,  8.5770e-04, -9.7709e-04,\n","                       3.5693e-03,  3.7570e-03,  7.3857e-04,  2.6946e-03, -3.2804e-04,\n","                       2.4222e-04, -4.4062e-03,  1.4088e-03, -5.4651e-04,  1.5560e-03,\n","                      -9.5248e-04,  4.5155e-04,  2.1152e-03,  1.2475e-04,  1.4638e-03,\n","                      -4.3354e-03,  2.8850e-03, -1.9521e-03,  3.0235e-03,  1.3900e-03,\n","                       2.9809e-03, -2.0608e-03, -2.3574e-03, -3.8532e-03,  3.1122e-04,\n","                       5.4534e-04,  2.6325e-03,  4.1533e-03,  2.2978e-05, -3.3145e-03,\n","                       4.8417e-03, -1.9610e-03, -1.7942e-03,  3.6567e-03,  1.0824e-03,\n","                       6.6694e-03, -7.2692e-04, -5.2461e-03,  7.1574e-03,  5.9654e-04,\n","                      -2.0341e-03,  1.9657e-03,  9.2398e-04, -4.0628e-03,  1.4509e-03,\n","                      -1.1803e-03, -3.9513e-03, -4.5342e-04,  2.5989e-03,  3.7509e-03,\n","                      -4.5214e-03,  1.0573e-03, -3.2953e-03, -2.3217e-03,  6.6036e-05,\n","                      -1.4297e-03, -5.4684e-03, -1.2100e-03,  4.0139e-03, -7.3414e-05,\n","                       5.3598e-03, -8.0871e-04,  6.2881e-04,  6.5217e-03, -7.4083e-03,\n","                      -3.5645e-03, -4.7626e-03,  5.9814e-03,  3.2092e-03,  1.7955e-03,\n","                      -8.4801e-03,  3.5878e-03, -6.3574e-03, -8.9930e-04, -5.1074e-03,\n","                      -2.8542e-03,  1.9027e-03, -1.0197e-03,  2.3678e-03, -3.9947e-03,\n","                      -1.1362e-04, -8.7884e-04,  1.8330e-03,  2.7242e-03,  3.0807e-03,\n","                      -3.0482e-03, -1.5501e-03,  3.2768e-04, -2.3508e-03,  6.1815e-03,\n","                      -1.7722e-03, -3.6969e-04, -5.3823e-03, -9.0354e-04, -4.0641e-03,\n","                       9.0716e-04, -1.3375e-03, -3.3555e-04, -2.5925e-03,  2.1692e-03,\n","                      -5.6210e-03, -1.6194e-03,  3.0413e-03, -2.2488e-03,  2.8566e-03,\n","                      -3.0290e-03,  1.0557e-03, -3.6593e-04,  1.7955e-03, -1.4505e-03,\n","                      -3.6810e-03, -1.1928e-03,  2.6349e-03,  1.6152e-03,  4.1854e-03,\n","                       4.2341e-04, -4.4222e-03, -1.9915e-03,  2.5989e-03, -1.3056e-03,\n","                       4.8213e-04,  4.2478e-03, -3.7347e-04, -1.1768e-03, -3.3930e-03,\n","                       2.0013e-03,  5.3976e-03, -1.6415e-03, -1.8520e-03, -4.8806e-03,\n","                      -2.7830e-03,  5.8314e-03, -1.5108e-03,  2.9588e-03,  1.6657e-03,\n","                       5.7305e-03,  1.2531e-03, -1.9216e-03,  5.8049e-03,  2.5933e-03,\n","                       1.7378e-03,  4.5008e-03, -4.2136e-04, -5.5571e-04, -1.0043e-03,\n","                      -7.2780e-03,  2.9955e-03, -5.4512e-03,  8.2862e-04,  3.9544e-03,\n","                       9.5215e-04,  1.3001e-03,  7.5084e-03,  3.0356e-03, -6.0543e-03,\n","                      -5.4838e-03,  6.9695e-03, -6.8197e-03,  1.5759e-03,  3.2091e-03,\n","                       3.3640e-03,  3.1234e-03, -4.0704e-03,  3.4035e-04,  4.9366e-04,\n","                       2.2993e-03,  2.9393e-03,  2.2886e-04,  2.7166e-03,  7.5895e-03,\n","                       1.0886e-03,  5.8728e-03, -5.9871e-03,  2.3191e-03, -3.6724e-03,\n","                       2.4313e-03,  7.4938e-04, -1.0087e-02,  1.8552e-03,  2.0737e-03,\n","                      -2.1037e-03, -1.9240e-03, -3.8664e-04,  3.0242e-03, -6.3981e-03,\n","                       6.0206e-04, -1.1718e-03,  1.0422e-03, -6.8207e-04,  2.1450e-03,\n","                       5.4252e-03, -5.1686e-04,  1.1492e-03,  3.4130e-03,  3.2106e-03,\n","                       1.3410e-03, -3.2418e-03, -5.8973e-04,  1.6274e-03, -1.5955e-03,\n","                      -3.0976e-03, -1.0183e-03, -3.3931e-03, -1.5712e-03, -4.7787e-03,\n","                       1.9310e-03,  3.5849e-03, -1.1109e-03, -2.7571e-03,  2.0230e-03,\n","                       3.3602e-03, -4.7631e-03, -4.2440e-03,  1.2152e-03, -3.7904e-03,\n","                      -1.2763e-03, -3.9143e-04, -1.3617e-04,  4.0944e-03, -6.4110e-04,\n","                      -2.6896e-03,  4.6793e-03, -1.4502e-03,  3.4283e-03,  1.7739e-03,\n","                       2.2639e-03, -3.8426e-03, -6.4193e-03, -5.0441e-04,  1.1181e-04,\n","                       4.7807e-03, -2.7235e-04,  5.5756e-03,  5.2065e-04, -7.7795e-04,\n","                      -2.8601e-03, -9.5950e-04, -4.4630e-03,  8.0005e-04,  5.2765e-03,\n","                       1.9887e-04,  1.3469e-03,  4.7652e-05, -1.8680e-03, -6.4546e-03,\n","                       2.1118e-03, -3.2720e-03,  1.1947e-03, -9.9300e-04, -1.5992e-03,\n","                       8.8623e-04,  1.7081e-03,  2.8175e-04, -8.8481e-04, -1.2022e-03,\n","                      -3.2281e-03,  1.3037e-03,  4.4769e-03,  1.2468e-03,  5.6994e-03,\n","                       2.5576e-03,  1.9203e-03,  3.8954e-04,  5.1818e-03,  6.6941e-05,\n","                      -2.8113e-03,  2.1715e-03, -1.1356e-03,  2.9933e-05, -2.2970e-03,\n","                      -4.4770e-04,  5.8798e-03,  4.3864e-03, -4.7616e-03, -5.0638e-03,\n","                      -1.3599e-03,  3.6359e-03, -1.7316e-03,  9.0690e-04, -4.3095e-04,\n","                      -3.6915e-03, -1.5306e-03, -4.0536e-03, -8.5235e-04, -3.0442e-03,\n","                       1.2858e-03,  6.9131e-04,  1.6009e-03,  1.7626e-03, -5.1651e-04,\n","                       6.4200e-04,  7.0947e-03, -1.0247e-03,  1.2007e-04, -1.3541e-04,\n","                       4.4663e-03,  2.5667e-03, -1.4585e-03, -1.4727e-03, -4.6446e-03,\n","                       5.1753e-03,  3.2653e-03, -5.6054e-04, -5.8617e-03, -1.5150e-03,\n","                       6.1601e-04,  3.4249e-03, -3.8574e-03, -8.6891e-04, -5.4772e-03,\n","                       2.0462e-03,  7.2710e-03, -2.2004e-03, -4.4892e-04, -5.9661e-03,\n","                      -6.5465e-03, -4.9780e-04, -4.5276e-03, -6.3022e-04, -2.5792e-03,\n","                       1.9230e-03,  1.0783e-03, -2.5059e-03, -1.8213e-03,  1.0311e-03,\n","                      -1.4030e-04, -2.3133e-03, -6.9141e-03,  2.4476e-03,  7.2197e-04,\n","                       2.2762e-03, -2.7110e-03,  4.3717e-03, -3.3890e-03, -9.8947e-04,\n","                      -2.9545e-03, -7.1844e-03, -3.8372e-04, -2.0018e-03,  1.8322e-03,\n","                       3.3068e-03, -5.4360e-03, -6.1038e-03, -2.6518e-03, -3.0697e-03,\n","                       1.8616e-03,  3.4538e-03, -2.5981e-03,  8.3889e-04,  5.3047e-03,\n","                      -1.9567e-03, -4.6325e-03,  3.4329e-03, -1.5306e-03, -1.6209e-03,\n","                       5.3114e-03,  2.3383e-03, -1.7781e-03, -3.5980e-03,  1.8989e-03,\n","                      -1.1414e-03, -6.6181e-03,  1.5204e-03,  2.3978e-03,  3.4700e-03,\n","                      -1.8587e-03, -5.8477e-03,  1.8682e-03, -1.6005e-03, -6.9083e-03,\n","                       4.3206e-04,  7.0534e-04, -1.0641e-02,  7.4577e-03, -3.7299e-03,\n","                      -3.7658e-03,  2.4566e-03, -2.6941e-03, -2.6638e-03,  6.0964e-03,\n","                      -6.3028e-03,  1.3689e-03, -9.2543e-04,  1.0582e-03,  5.0610e-03,\n","                      -4.0280e-04,  3.3492e-03, -4.5935e-04, -6.3774e-03, -4.1558e-03,\n","                      -5.3611e-03,  4.0311e-04, -2.5249e-04, -5.4671e-03, -2.2087e-03,\n","                       4.7625e-04, -3.2149e-03, -3.4995e-03, -6.1473e-04, -7.6577e-03,\n","                      -8.5384e-03,  3.5407e-03, -3.0268e-03, -2.2978e-04,  3.0952e-03,\n","                       4.7139e-04,  3.0270e-03,  4.9703e-03, -6.8809e-03,  2.0515e-04,\n","                       1.3801e-03,  2.0221e-03, -2.6415e-03,  8.5357e-03,  5.1480e-03,\n","                       1.1343e-03, -8.2558e-04,  2.3710e-03, -1.1749e-03, -5.6846e-03,\n","                      -2.5468e-03, -4.3375e-03,  4.2871e-04, -2.9236e-03, -5.0993e-03,\n","                       1.3504e-03,  2.8693e-03,  3.6525e-03, -2.4303e-03, -4.9913e-05,\n","                       2.7100e-03, -2.6473e-03], device='cuda:0')),\n","             ('model.layers.11.running_mean',\n","              tensor([[-6.1418e-02,  9.7012e-02,  7.7096e-02,  2.3684e-02,  6.8394e-02,\n","                       -4.9275e-02,  2.0019e-02, -8.1623e-02,  1.1900e-02, -6.3562e-02,\n","                       -6.1746e-02, -1.3872e-01,  4.1295e-02, -6.0115e-03, -4.8797e-02,\n","                       -6.0504e-02,  1.0674e-01, -8.1966e-02,  3.1262e-02, -6.1680e-02,\n","                       -1.4144e-01, -4.0952e-02,  1.9732e-01, -4.2148e-02, -3.3129e-03,\n","                        6.7845e-02, -1.6853e-01,  6.6728e-02, -5.1356e-02,  7.5420e-02,\n","                        3.1600e-03, -3.3630e-03,  8.7465e-02, -2.7564e-02,  1.2691e-01,\n","                        3.1281e-03, -3.0210e-02, -4.8484e-02,  8.3819e-02,  2.5129e-03,\n","                       -1.5245e-02,  3.2566e-02,  2.8194e-02, -5.5505e-02, -3.7039e-02,\n","                       -8.1187e-02, -9.3575e-03, -3.2224e-02,  2.5953e-02,  1.7657e-02,\n","                       -8.6321e-02,  2.1926e-02, -1.0322e-01, -2.6689e-02, -1.9816e-02,\n","                       -4.4376e-02,  5.0783e-02,  1.3845e-01, -5.5570e-02,  5.6689e-02,\n","                       -1.3304e-02,  5.8633e-02, -1.8874e-02, -8.7190e-02,  3.4046e-02,\n","                       -4.6159e-02,  6.3104e-03,  3.3885e-02, -1.7107e-04,  2.9828e-02,\n","                       -9.8541e-02,  2.8766e-02, -5.4383e-02,  6.4854e-02, -4.8651e-02,\n","                       -7.2673e-02, -1.0059e-01, -5.0739e-02,  3.8068e-02,  2.2678e-02,\n","                       -7.9553e-02, -1.4244e-01, -8.6853e-02, -6.3261e-02,  9.1196e-02,\n","                       -5.2544e-02,  4.4454e-02,  2.6225e-02, -8.0550e-02,  3.4626e-02,\n","                        2.6410e-02,  4.8054e-02, -4.0152e-02, -1.0213e-01,  2.4881e-02,\n","                        8.9326e-02,  9.4120e-03, -1.2220e-01,  2.0407e-02, -3.3297e-02,\n","                        2.3220e-02, -5.0016e-02, -7.4675e-02,  8.5392e-03, -7.3424e-02,\n","                       -9.8072e-02,  2.4437e-02, -8.3692e-02, -3.7708e-02, -5.3372e-02,\n","                        6.7279e-02,  7.7970e-02,  2.8441e-02, -3.6109e-02, -6.9784e-02,\n","                       -3.5949e-02,  5.5462e-02, -4.0865e-03, -3.6311e-02, -9.8512e-02,\n","                       -5.4885e-02, -7.8648e-02,  7.4590e-02, -5.7224e-02,  1.7539e-02,\n","                       -3.6639e-02,  2.2236e-02, -1.7459e-02,  2.5726e-02, -3.8175e-02,\n","                       -1.1306e-02,  6.8110e-04,  1.4721e-02, -3.8787e-02,  5.9914e-02,\n","                        2.4325e-02,  6.9192e-02, -4.1412e-02,  2.2658e-02, -8.1359e-03,\n","                       -5.2221e-03, -2.2167e-02, -7.8332e-04, -5.5124e-02, -4.4135e-03,\n","                       -4.1227e-02,  2.2441e-03, -4.6198e-02,  1.2436e-02, -7.3992e-02,\n","                        7.5470e-03,  1.4825e-02,  4.9024e-02, -4.8358e-02, -9.3068e-04,\n","                        6.7420e-02, -6.7669e-02, -1.1280e-01, -4.1092e-02, -3.6881e-02,\n","                       -7.8818e-03,  1.1387e-02, -9.3533e-03,  3.0013e-02,  3.5812e-02,\n","                        2.0354e-02, -4.7042e-02,  3.4958e-02, -1.5811e-02, -8.4057e-02,\n","                        8.7062e-02, -2.4019e-02,  1.1262e-01,  4.4606e-02, -2.3808e-02,\n","                        5.2261e-02,  7.3095e-02,  5.9524e-02,  5.2813e-02,  8.1548e-04,\n","                        3.4783e-02,  4.6476e-03, -4.0834e-02,  2.6399e-02,  8.8889e-03,\n","                        1.0937e-01,  1.7662e-02, -1.4631e-03, -7.8140e-02, -4.2678e-02,\n","                        1.3191e-02, -9.5440e-02, -5.5942e-02, -7.3387e-02,  9.0482e-03,\n","                       -2.4707e-03, -1.0164e-02, -3.3211e-02,  9.0376e-02, -9.8540e-03,\n","                       -6.7230e-02,  8.1477e-02, -7.8182e-02,  5.2925e-02,  3.8298e-02,\n","                       -6.2441e-02, -6.2861e-02,  1.1826e-02,  8.1141e-02,  1.6380e-02,\n","                       -5.1442e-02,  7.3783e-02,  3.5669e-02,  1.7104e-02,  7.1253e-02,\n","                       -9.5444e-03, -5.8642e-02, -1.8081e-02, -4.0470e-02,  1.5015e-03,\n","                       -1.0042e-02, -7.4259e-02, -1.5209e-03, -1.6099e-02, -2.2159e-02,\n","                        5.2937e-02,  6.4791e-02, -1.3420e-02, -7.1349e-02, -7.5550e-02,\n","                       -4.2295e-02, -2.5694e-02, -4.8479e-02,  1.1565e-02,  9.7811e-02,\n","                        2.6878e-02, -7.7103e-02, -4.6277e-02, -3.8833e-02,  1.4166e-02,\n","                        3.6940e-02, -8.5275e-02, -4.1428e-02,  6.7413e-02, -5.0279e-02,\n","                        3.5954e-02,  6.0857e-02, -4.2583e-02,  7.5239e-02, -1.3985e-01,\n","                        4.9642e-03, -1.0787e-01,  6.5424e-02, -1.9037e-02,  1.8102e-02,\n","                       -2.3506e-02,  5.5997e-02,  1.0377e-01, -3.8543e-02, -1.7400e-02,\n","                        1.0946e-02,  3.6420e-03,  7.9264e-03,  7.6036e-03,  3.3286e-02,\n","                       -1.5538e-02, -1.9107e-02, -8.3703e-02,  2.6340e-02,  1.6246e-02,\n","                       -4.1322e-02, -6.0668e-02, -4.0861e-02,  3.3482e-02,  2.0013e-02,\n","                        6.4041e-02,  7.0163e-02,  9.6560e-02, -5.9818e-02,  1.0902e-02,\n","                        6.1518e-02, -4.9136e-03, -1.9115e-02, -2.7661e-02,  1.0739e-01,\n","                        5.8114e-02, -1.8153e-02,  7.8069e-03, -2.0874e-02,  3.4555e-02,\n","                       -3.7986e-02, -1.2046e-02, -1.3916e-01, -6.6287e-02, -1.0147e-02,\n","                       -3.6428e-02,  1.4628e-01,  4.0743e-02,  8.1285e-02,  2.8014e-02,\n","                        3.1486e-02, -1.0070e-01,  4.0763e-02, -2.8875e-02, -2.6234e-02,\n","                       -5.2671e-02, -7.1396e-03,  4.0210e-02,  5.8932e-02,  5.9841e-02,\n","                       -5.8137e-02, -2.0461e-02, -5.2287e-02, -2.4881e-02,  4.8907e-02,\n","                       -7.4281e-02, -4.6116e-03, -8.6474e-02,  4.0446e-03,  8.5236e-03,\n","                        5.4197e-02,  1.5397e-02,  7.1110e-02, -2.2229e-02,  2.1852e-02,\n","                        7.6413e-02, -5.0963e-02,  6.9546e-02,  1.1652e-01, -3.1131e-02,\n","                       -1.5374e-02,  1.8222e-02, -5.6997e-02, -6.1069e-03,  8.0755e-02,\n","                       -1.0900e-02, -3.2508e-03, -1.5289e-01, -1.1626e-01, -1.5840e-01,\n","                        2.7907e-02, -7.9812e-02,  9.6258e-03, -1.0363e-01,  5.8398e-02,\n","                        6.3827e-02,  1.4175e-02, -4.0909e-02, -5.6487e-02,  1.2754e-02,\n","                        2.3977e-02,  1.9933e-03,  1.3789e-02, -2.2645e-02, -1.5371e-01,\n","                       -4.4283e-02,  5.9230e-03,  3.7039e-02,  1.1157e-01,  1.6195e-02,\n","                       -1.3328e-01, -2.0346e-02,  4.8485e-02,  5.2269e-02, -2.0485e-02,\n","                        5.4135e-02,  7.7519e-02,  1.6895e-02,  3.4670e-02,  3.5464e-02,\n","                        8.7734e-02, -6.3231e-02,  4.0559e-02, -1.6669e-02,  5.3639e-02,\n","                       -4.9201e-02,  8.5575e-02,  3.1960e-02,  1.0053e-01,  9.3879e-03,\n","                       -5.6935e-02,  6.1953e-02, -9.5034e-03, -4.2222e-02, -1.8779e-02,\n","                       -3.9633e-02,  5.5978e-02,  5.2750e-02, -1.9208e-02,  5.5259e-02,\n","                        1.8507e-02,  9.9481e-02, -2.1638e-02,  3.1422e-02,  1.2757e-01,\n","                        6.1187e-02, -9.9459e-02,  8.9066e-02,  4.2135e-02,  1.0203e-05,\n","                        1.2163e-01, -6.2825e-02,  6.4298e-02,  7.0557e-02,  8.8861e-02,\n","                        7.7968e-02, -8.8619e-03,  1.0507e-01, -4.9042e-02,  1.6813e-04,\n","                       -4.3395e-03,  5.2680e-03,  7.0904e-03, -5.7592e-02,  2.5940e-02,\n","                        5.7400e-02, -3.3561e-02,  1.9626e-01,  1.7991e-02,  2.8637e-02,\n","                       -1.4794e-02,  2.4292e-03, -3.2216e-02, -1.4538e-02, -8.7492e-03,\n","                        1.0703e-01,  4.8441e-02,  6.4158e-02,  2.6534e-02, -4.6451e-02,\n","                       -2.5375e-03, -1.1252e-01,  8.3005e-03, -3.1033e-03,  1.0792e-02,\n","                       -6.0571e-02, -1.7765e-02,  4.0795e-02, -1.3972e-01, -1.3246e-01,\n","                       -1.3823e-01, -7.7261e-02, -1.1967e-02,  4.7959e-02, -5.3939e-02,\n","                        2.1471e-02,  4.4703e-02,  1.0990e-03, -6.3306e-02,  1.3385e-02,\n","                        4.5035e-02,  5.4593e-02, -1.4053e-02,  6.4028e-02, -1.8328e-02,\n","                       -1.6302e-01,  2.4096e-02,  7.5187e-02, -2.4584e-03,  2.8165e-02,\n","                       -1.0326e-01,  2.0345e-02, -2.3903e-02,  3.2303e-02, -1.1433e-01,\n","                        3.8538e-02,  3.3384e-02, -1.2572e-01,  1.0271e-01,  1.1573e-01,\n","                        1.2579e-01,  1.3507e-02,  2.8419e-03,  1.2705e-01,  1.8808e-02,\n","                        2.2040e-02, -4.3262e-02,  4.5931e-02, -2.3169e-02, -4.1210e-02,\n","                        9.3522e-03,  1.6022e-02, -7.2976e-02, -5.5797e-02, -1.0606e-01,\n","                       -9.4546e-02,  1.0096e-01, -4.8418e-02, -8.9581e-02, -4.3418e-02,\n","                        8.2080e-02, -4.2156e-02,  2.8158e-02,  1.3063e-02, -6.9230e-02,\n","                        2.2360e-02,  8.9406e-03,  6.0701e-02, -7.1551e-02, -5.5459e-02,\n","                        6.8228e-02,  7.6784e-03, -1.3632e-02, -1.4101e-02,  6.7353e-02,\n","                       -1.1817e-03,  4.0363e-02, -1.2027e-01, -3.1064e-03,  3.0862e-02,\n","                       -6.0167e-02,  5.0137e-02]], device='cuda:0')),\n","             ('model.layers.11.running_var',\n","              tensor([[0.3853, 0.1924, 0.3858, 0.2757, 0.2618, 0.2366, 0.4705, 0.2732, 0.2361,\n","                       0.5532, 0.2297, 0.4493, 0.2669, 0.3953, 0.3673, 0.2400, 0.3455, 0.3087,\n","                       0.2203, 0.2663, 0.2491, 0.2675, 0.3801, 0.2475, 0.2793, 0.2344, 0.3629,\n","                       0.2487, 0.3240, 0.3261, 0.2236, 0.5797, 0.3654, 0.2055, 0.2545, 0.2147,\n","                       0.3174, 0.3661, 0.1750, 0.2594, 0.2771, 0.4433, 0.2078, 0.2966, 0.3173,\n","                       0.5769, 0.3369, 0.2660, 0.5205, 0.4862, 0.2315, 0.2195, 0.1652, 0.3503,\n","                       0.2816, 0.4504, 0.3394, 0.1620, 0.2140, 0.2841, 0.2582, 0.4066, 0.2226,\n","                       0.2646, 0.2284, 0.4406, 0.2641, 0.2244, 0.1868, 0.1604, 0.2383, 0.3507,\n","                       0.2161, 0.1897, 0.1916, 0.2782, 0.4822, 0.2706, 0.2082, 0.3337, 0.4968,\n","                       0.4003, 0.5657, 0.2364, 0.3417, 0.3359, 0.3336, 0.2861, 0.2459, 0.3618,\n","                       0.3652, 0.2911, 0.2230, 0.1951, 0.1615, 0.5235, 0.3416, 0.3155, 0.2304,\n","                       0.3142, 0.2157, 0.3710, 0.2147, 0.5025, 0.2067, 0.2926, 0.2780, 0.5036,\n","                       0.3309, 0.2928, 0.1896, 0.3142, 0.3972, 0.2998, 0.3479, 0.3327, 0.2422,\n","                       0.4867, 0.4842, 0.1893, 0.2703, 0.2456, 0.2591, 0.3101, 0.1689, 0.3665,\n","                       0.2657, 0.1746, 0.2768, 0.3306, 0.2789, 0.4219, 0.2972, 0.2614, 0.2202,\n","                       0.3803, 0.2281, 0.2905, 0.3849, 0.1921, 0.3538, 0.1979, 0.3349, 0.3182,\n","                       0.4915, 0.2252, 0.2648, 0.2628, 0.4697, 0.2629, 0.3989, 0.3446, 0.3649,\n","                       0.2736, 0.4506, 0.1713, 0.3117, 0.2642, 0.2817, 0.3583, 0.2223, 0.3795,\n","                       0.2344, 0.2270, 0.1817, 0.3329, 0.2929, 0.2786, 0.2962, 0.3075, 0.4148,\n","                       0.2065, 0.2984, 0.2308, 0.2024, 0.3755, 0.3040, 0.3636, 0.3592, 0.3028,\n","                       0.2710, 0.2030, 0.1939, 0.1970, 0.2304, 0.2554, 0.3079, 0.3223, 0.5049,\n","                       0.1998, 0.2978, 0.3541, 0.3910, 0.2895, 0.3283, 0.2403, 0.2254, 0.3146,\n","                       0.4977, 0.2887, 0.3280, 0.2190, 0.2725, 0.2887, 0.2298, 0.2478, 0.3353,\n","                       0.5307, 0.2939, 0.4772, 0.4616, 0.4900, 0.3514, 0.3005, 0.2250, 0.2677,\n","                       0.2879, 0.3567, 0.5111, 0.1948, 0.1909, 0.3140, 0.3233, 0.2436, 0.2892,\n","                       0.3546, 0.2651, 0.2871, 0.2743, 0.2847, 0.1743, 0.3140, 0.5257, 0.2364,\n","                       0.2328, 0.2373, 0.2421, 0.2152, 0.2345, 0.3402, 0.2337, 0.2418, 0.3158,\n","                       0.2457, 0.1891, 0.3810, 0.2402, 0.3476, 0.3707, 0.2883, 0.2911, 0.1819,\n","                       0.3958, 0.2608, 0.3604, 0.3969, 0.2815, 0.3723, 0.2600, 0.2372, 0.2019,\n","                       0.2596, 0.1894, 0.2491, 0.3112, 0.3010, 0.2596, 0.3385, 0.2924, 0.3498,\n","                       0.3736, 0.1719, 0.2521, 0.2385, 0.3106, 0.3241, 0.3104, 0.3048, 0.3053,\n","                       0.4805, 0.2917, 0.2802, 0.2136, 0.3318, 0.4308, 0.2816, 0.4152, 0.2711,\n","                       0.3445, 0.4021, 0.2795, 0.2809, 0.3355, 0.5406, 0.5339, 0.3254, 0.3045,\n","                       0.3597, 0.2730, 0.2364, 0.3802, 0.3770, 0.1588, 0.2176, 0.2773, 0.2429,\n","                       0.6463, 0.3177, 0.3258, 0.2446, 0.3397, 0.3839, 0.1988, 0.3250, 0.2011,\n","                       0.3358, 0.3234, 0.2184, 0.3318, 0.5102, 0.2985, 0.2993, 0.2052, 0.5260,\n","                       0.7427, 0.2814, 0.3217, 0.3780, 0.3390, 0.1706, 0.2650, 0.2038, 0.3264,\n","                       0.1905, 0.2599, 0.3726, 0.4847, 0.2477, 0.3382, 0.3312, 0.2682, 0.2905,\n","                       0.2525, 0.4277, 0.2358, 0.2871, 0.1864, 0.2987, 0.2221, 0.4375, 0.3321,\n","                       0.3779, 0.4066, 0.4246, 0.2668, 0.1837, 0.5178, 0.3224, 0.2175, 0.2806,\n","                       0.4305, 0.2312, 0.2978, 0.3260, 0.3536, 0.2920, 0.2134, 0.1832, 0.3149,\n","                       0.3123, 0.3223, 0.4134, 0.3730, 0.3118, 0.3035, 0.2165, 0.3761, 0.3192,\n","                       0.2632, 0.2549, 0.2797, 0.3438, 0.3338, 0.3796, 0.3099, 0.2305, 0.1879,\n","                       0.2800, 0.3831, 0.2176, 0.4521, 0.4663, 0.3356, 0.3220, 0.2253, 0.3205,\n","                       0.3207, 0.2735, 0.3698, 0.2333, 0.5029, 0.2495, 0.3047, 0.3269, 0.2178,\n","                       0.2889, 0.2982, 0.3769, 0.2348, 0.3452, 0.1814, 0.2668, 0.2138, 0.1945,\n","                       0.1740, 0.3270, 0.4132, 0.4754, 0.2298, 0.1942, 0.3452, 0.5347, 0.8814,\n","                       0.2778, 0.3526, 0.3182, 0.2478, 0.2885, 0.2967, 0.3759, 0.3613, 0.3316,\n","                       0.2957, 0.2099, 0.4620, 0.3693, 0.2037, 0.2788, 0.3850, 0.3293, 0.2882,\n","                       0.3923, 0.2244, 0.3682, 0.2490, 0.2880, 0.2517, 0.3132, 0.4610, 0.2894,\n","                       0.2284, 0.2290, 0.3971, 0.5570, 0.4363, 0.4568, 0.2942, 0.2243, 0.3678,\n","                       0.3189, 0.3265, 0.2029, 0.2669, 0.1867, 0.2902, 0.2631, 0.3692, 0.3989,\n","                       0.4758, 0.2698, 0.5105, 0.4048, 0.3135, 0.2244, 0.2502, 0.2405, 0.2094,\n","                       0.3286, 0.2473, 0.3683, 0.2519, 0.1794, 0.2503, 0.2516, 0.4374, 0.1966,\n","                       0.4159, 0.2754, 0.8442, 0.2460, 0.2939, 0.2708, 0.2193, 0.5380, 0.4097,\n","                       0.2970, 0.2255, 0.3250, 0.2261, 0.3929, 0.3136, 0.1841, 0.2019, 0.3685,\n","                       0.3075, 0.2726, 0.5033, 0.3197, 0.3183, 0.2793, 0.2802, 0.3696]],\n","                     device='cuda:0')),\n","             ('model.layers.13.weight',\n","              tensor([[ 0.0606,  0.0164, -0.0642,  ..., -0.0152, -0.0147, -0.0106],\n","                      [-0.0414,  0.0065, -0.0316,  ...,  0.0140,  0.0226,  0.0742],\n","                      [-0.0055, -0.0194, -0.0108,  ..., -0.0093,  0.0316,  0.0058],\n","                      ...,\n","                      [ 0.0136, -0.0046,  0.0049,  ...,  0.0140,  0.0092, -0.0287],\n","                      [-0.0228, -0.0021,  0.0350,  ...,  0.0067,  0.0018, -0.0182],\n","                      [-0.0058, -0.0220,  0.0320,  ..., -0.0114,  0.0150, -0.0173]],\n","                     device='cuda:0')),\n","             ('model.layers.13.bias',\n","              tensor([ 0.0044, -0.0557,  0.1274, -0.0248,  0.0004,  0.0254,  0.0540, -0.0158,\n","                       0.0152, -0.0311, -0.0411, -0.0149, -0.0386, -0.0367,  0.0778,  0.0053,\n","                       0.0181,  0.0415,  0.0241, -0.0570,  0.0268, -0.0068,  0.0237, -0.0977,\n","                       0.0085,  0.0272,  0.0291,  0.0556,  0.0014, -0.0291,  0.0419,  0.0331,\n","                       0.0192,  0.0343, -0.0617, -0.0489, -0.0738, -0.0336, -0.0268],\n","                     device='cuda:0'))])"]},"metadata":{},"execution_count":43}]},{"cell_type":"code","source":["# Assuming you have loaded the model as shown in the previous response\n","# and put it into evaluation mode using model.eval()\n","\n","# Sample from the model\n","for _ in range(50):\n","    out = []\n","    context = [0] * block_size  # initialize with all ...\n","\n","    with torch.no_grad():\n","        while True:\n","            # Convert the context to a tensor and transfer it to the device\n","            context_tensor = torch.tensor([context])\n","            context_tensor = context_tensor.to(device)  # Assuming 'device' is properly defined\n","\n","            # Forward pass the neural net\n","            logits = loaded_model(context_tensor)\n","            probs = F.softmax(logits, dim=1)\n","\n","            # Sample from the distribution\n","            ix = torch.multinomial(probs, num_samples=1).item()\n","\n","            # Shift the context window and track the samples\n","            context = context[1:] + [ix]\n","            out.append(ix)\n","\n","            # If we sample the special '.' token, break\n","            if ix == 0:\n","                break\n","\n","    generated_text = ''.join(itos[i] for i in out)  # Decode the generated word\n","    #print(len(set(out)))\n","    print(generated_text.replace(\"*\",\"\"))  # Print the generated text for each iteration\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JG3-7054huX2","executionInfo":{"status":"ok","timestamp":1690397292974,"user_tz":-330,"elapsed":1750,"user":{"displayName":"Santosh Bhamidipati","userId":"03330145564595875028"}},"outputId":"dbcf3ca7-cb8d-494b-c629-7dbd97a00f8b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["thsnitedu1akady,n01,20142\n","bbobinil,4mbia,cun,2014,1.73\n","nitedek,nga,2014,1.79\n","arkana,chr,2014,1.74\n","northigl,201\n","beninw,gen,2014,1.8y\n","iargandjdflani,2de,20ce,3.pal,xde,2s14y0.21,p0k87\n","unin,h5a,2014,6.22\n","mali,iti,2014,33w4\n","china,chl,2014,1.88\n","pawime,m,kzra281tan,kdug2nm,fd,222,2014,3.01\n","bolgaria,bya,2014,1.75\n","argentura,den,2014,3.24\n","bolia,ihm,ns,52014,1.99\n","switzerlan,syn,2014,1.56\n","stmbra,2s14,2.4\n","portugakmaga,1tu,2014,3.88\n","switer,l0is,1.19\n","gbunimedvn s593d2fia,upa,2014,5.25\n","swtoemaia,gou,2014,3.88\n","poland,pol,2014,2.35\n","oolania,rrg,2014,3.24\n","lgarda,nld,2014,1.41\n","niusarbhn,,chs,2014,1.73\n","maakggytu0ktra,ph4,2014,3.75\n","arnica,cul,2014,1.75\n","united kin0dom,20ka,3\n","finland,nin,2014,1.92\n","costm rado,tni,2014,1.81\n","estonia,,4dux,1od,2014,2.01\n","sestenss,es n8,1rg,2014,2.98\n","vrloydom,2014,2.64\n","aunir,eug,2014,1.79\n","relosla,rdo,2014,4.25\n","colomda,cen,2014,3.33\n","hgaagesy,nin,2014,4.88\n","kkhes9mw,ige,2014,m.21\n","swoden,s.e,2014,1.58\n","ghatk ria, fr,2014,1.8\n","sthorla,,go922044j\n","swite,uss,2014,1.95\n","spain,tza,2014,3.81\n","etumkex,tud,2014,3.85\n","aexiandcn,7za,2014,j.01\n","colezdin,gth,2014,4.28\n","albedtnus,ru1u2014,1.86\n","romania,del,2014,1.61\n","etuva7ica,niu,2014,1.37\n","kaugar,2014,1.77\n","colomaiccarcma,ugi,2014,15h250\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"a2pyEtYgh6-e"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"}},"nbformat":4,"nbformat_minor":0}